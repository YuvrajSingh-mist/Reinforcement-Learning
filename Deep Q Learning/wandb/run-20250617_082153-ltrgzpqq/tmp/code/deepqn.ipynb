{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import time\n",
    "import gymnasium as gym\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from stable_baselines3.common.buffers import ReplayBuffer\n",
    "import wandb\n",
    "from huggingface_hub import HfApi, upload_folder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ===== CONFIGURATION =====\n",
    "class Config:\n",
    "    # Experiment settings\n",
    "    exp_name = \"DQN-CartPole\"\n",
    "    seed = 42\n",
    "    env_id = \"CartPole-v1\"\n",
    "    \n",
    "    # Training parameters\n",
    "    total_timesteps = 10000\n",
    "    learning_rate = 2.5e-4\n",
    "    buffer_size = 10000\n",
    "    gamma = 0.99\n",
    "    tau = 1.0\n",
    "    target_network_frequency = 500\n",
    "    batch_size = 128\n",
    "    start_e = 1.0\n",
    "    end_e = 0.05\n",
    "    exploration_fraction = 0.5\n",
    "    learning_starts = 1000\n",
    "    train_frequency = 10\n",
    "    \n",
    "    # Logging & saving\n",
    "    capture_video = True\n",
    "    save_model = True\n",
    "    upload_model = True\n",
    "    hf_entity = \"\"  # Your Hugging Face username\n",
    "    \n",
    "    # WandB settings\n",
    "    use_wandb = True\n",
    "    wandb_project = \"cleanRL\"\n",
    "    wandb_entity = \"\"  # Your WandB username/team\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QNet(nn.Module):\n",
    "    def __init__(self, state_space, action_space):\n",
    "        super(QNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(state_space, 256)\n",
    "        self.fc2 = nn.Linear(256, 512)\n",
    "        self.q_value = nn.Linear(512, action_space)\n",
    "    def forward(self, x):\n",
    "        return self.q_value(torch.relu(self.fc2(torch.relu(self.fc1(x)))))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearEpsilonDecay(nn.Module):\n",
    "    def __init__(self, initial_eps, end_eps,total_timesteps):\n",
    "        super(LinearEpsilonDecay, self).__init__()\n",
    "        self.initial_eps = initial_eps\n",
    "        # self.decay_factor = decay_factor\n",
    "        self.total_timesteps = total_timesteps\n",
    "        self.end_eps = end_eps\n",
    "        \n",
    "        \n",
    "    def forward(self, x, current_timestep):\n",
    "        slope = (self.end_eps - self.initial_eps) / (exploration_fraction * self.total_timesteps)\n",
    "        return max(slope * current_timestep + self.initial_eps, self.end_eps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_env(env_id, seed, capture_video, run_name, eval_mode=False):\n",
    "    \"\"\"Create environment with video recording\"\"\"\n",
    "    env = gym.make(env_id, render_mode=\"rgb_array\")\n",
    "    env = gym.wrappers.RecordEpisodeStatistics(env)\n",
    "    \n",
    "    # Video recording setup\n",
    "    if capture_video:\n",
    "        if eval_mode:\n",
    "            # Evaluation videos\n",
    "            video_prefix = f\"videos/{run_name}/eval\"\n",
    "        else:\n",
    "            # Training videos\n",
    "            video_prefix = f\"videos/{run_name}/train\"\n",
    "            env = gym.wrappers.RecordVideo(\n",
    "                env, \n",
    "                video_prefix,\n",
    "                episode_trigger=lambda x: x % 100 == 0  # Record every 100 episodes\n",
    "            )\n",
    "    \n",
    "    env.action_space.seed(seed)\n",
    "    return env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, env, device, run_name, eps_decay, num_eval_eps = 10):\n",
    "    eval_env = make_env(env_id=Config.env_id, seed=Config.seed, capture_video=True, run_name=run_name, eval_mode=True)\n",
    "    eval_env.action_space.seed(Config.seed)\n",
    "    \n",
    "    model = model.to(device)\n",
    "    model = model.eval()\n",
    "    \n",
    "    \n",
    "    returns = []\n",
    "    frames = []\n",
    "    \n",
    "    for eps in tqdm(range(num_eval_eps)):\n",
    "        obs, _ = eval_env.reset()\n",
    "        done = False\n",
    "        rewards = 0.0\n",
    "        \n",
    "        while not done:\n",
    "            state_space = torch.tensor(obs, dtype=torch.float32).to(device)\n",
    "            q_val = model(state_space.unsqueeze(0))\n",
    "            q_new = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mrajceo2031\u001b[0m (\u001b[33mrentio\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "creating run (0.2s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/c/Users/yuvra/OneDrive/Desktop/Work/pytorch/RL/Deep Q Learning/wandb/run-20250617_082153-ltrgzpqq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/rentio/cleanRL/runs/ltrgzpqq' target=\"_blank\">CartPole-v1__DQN-CartPole__42__1750148511</a></strong> to <a href='https://wandb.ai/rentio/cleanRL' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/rentio/cleanRL' target=\"_blank\">https://wandb.ai/rentio/cleanRL</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/rentio/cleanRL/runs/ltrgzpqq' target=\"_blank\">https://wandb.ai/rentio/cleanRL/runs/ltrgzpqq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "args = Config()\n",
    "run_name = f\"{args.env_id}__{args.exp_name}__{args.seed}__{int(time.time())}\"\n",
    "\n",
    " # Initialize WandB\n",
    "if args.use_wandb:\n",
    "        wandb.init(\n",
    "            project=args.wandb_project,\n",
    "            entity=args.wandb_entity,\n",
    "            sync_tensorboard=True,\n",
    "            config=vars(args),\n",
    "            name=run_name,\n",
    "            monitor_gym=True,\n",
    "            save_code=True,\n",
    "        )\n",
    "os.makedirs(f\"videos/{run_name}/train\", exist_ok=True)\n",
    "os.makedirs(f\"videos/{run_name}/eval\", exist_ok=True)\n",
    "os.makedirs(f\"runs/{run_name}\", exist_ok=True)\n",
    "writer = SummaryWriter(f\"runs/{run_name}\")\n",
    "    \n",
    "    # Set seeds\n",
    "random.seed(args.seed)\n",
    "np.random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = make_env(args.env_id, args.seed, args.capture_video, run_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_net = Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
