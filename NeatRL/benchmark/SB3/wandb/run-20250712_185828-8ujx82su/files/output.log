Using cuda device
/home/yuvrajsingh/anaconda3/envs/mt/lib/python3.11/site-packages/stable_baselines3/common/on_policy_algorithm.py:150: UserWarning: You are trying to run PPO on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.
  warnings.warn(
ActorCriticPolicy(
  (features_extractor): FlattenExtractor(
    (flatten): Flatten(start_dim=1, end_dim=-1)
  )
  (pi_features_extractor): FlattenExtractor(
    (flatten): Flatten(start_dim=1, end_dim=-1)
  )
  (vf_features_extractor): FlattenExtractor(
    (flatten): Flatten(start_dim=1, end_dim=-1)
  )
  (mlp_extractor): MlpExtractor(
    (policy_net): Sequential(
      (0): Linear(in_features=17, out_features=64, bias=True)
      (1): Tanh()
      (2): Linear(in_features=64, out_features=64, bias=True)
      (3): Tanh()
    )
    (value_net): Sequential(
      (0): Linear(in_features=17, out_features=64, bias=True)
      (1): Tanh()
      (2): Linear(in_features=64, out_features=64, bias=True)
      (3): Tanh()
    )
  )
  (action_net): Linear(in_features=64, out_features=6, bias=True)
  (value_net): Linear(in_features=64, out_features=1, bias=True)
)
Traceback (most recent call last):
  File "/mnt/c/Users/yuvra/OneDrive/Desktop/Work/pytorch/RL/PPO/MuJoCo/benchmark/SB3/half-cheetah-sb3.py", line 190, in <module>
    model.learn(
  File "/home/yuvrajsingh/anaconda3/envs/mt/lib/python3.11/site-packages/stable_baselines3/ppo/ppo.py", line 311, in learn
    return super().learn(
           ^^^^^^^^^^^^^^
  File "/home/yuvrajsingh/anaconda3/envs/mt/lib/python3.11/site-packages/stable_baselines3/common/on_policy_algorithm.py", line 319, in learn
    callback.on_training_start(locals(), globals())
  File "/home/yuvrajsingh/anaconda3/envs/mt/lib/python3.11/site-packages/stable_baselines3/common/callbacks.py", line 84, in on_training_start
    self._on_training_start()
  File "/home/yuvrajsingh/anaconda3/envs/mt/lib/python3.11/site-packages/stable_baselines3/common/callbacks.py", line 213, in _on_training_start
    callback.on_training_start(self.locals, self.globals)
  File "/home/yuvrajsingh/anaconda3/envs/mt/lib/python3.11/site-packages/stable_baselines3/common/callbacks.py", line 84, in on_training_start
    self._on_training_start()
  File "/mnt/c/Users/yuvra/OneDrive/Desktop/Work/pytorch/RL/PPO/MuJoCo/benchmark/SB3/half-cheetah-sb3.py", line 29, in _on_training_start
    self.pbar = tqdm(total=self.training_env.total_timesteps, desc="Training Progress")
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yuvrajsingh/anaconda3/envs/mt/lib/python3.11/site-packages/stable_baselines3/common/vec_env/base_vec_env.py", line 439, in __getattr__
    return self.getattr_recursive(name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yuvrajsingh/anaconda3/envs/mt/lib/python3.11/site-packages/stable_baselines3/common/vec_env/base_vec_env.py", line 464, in getattr_recursive
    attr = getattr(self.venv, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'DummyVecEnv' object has no attribute 'total_timesteps'
