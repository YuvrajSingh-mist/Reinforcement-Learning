Using cuda device
/home/yuvrajsingh/anaconda3/envs/mt/lib/python3.11/site-packages/stable_baselines3/common/on_policy_algorithm.py:150: UserWarning: You are trying to run PPO on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.
  warnings.warn(
ActorCriticPolicy(
  (features_extractor): FlattenExtractor(
    (flatten): Flatten(start_dim=1, end_dim=-1)
  )
  (pi_features_extractor): FlattenExtractor(
    (flatten): Flatten(start_dim=1, end_dim=-1)
  )
  (vf_features_extractor): FlattenExtractor(
    (flatten): Flatten(start_dim=1, end_dim=-1)
  )
  (mlp_extractor): MlpExtractor(
    (policy_net): Sequential(
      (0): Linear(in_features=17, out_features=64, bias=True)
      (1): Tanh()
      (2): Linear(in_features=64, out_features=64, bias=True)
      (3): Tanh()
    )
    (value_net): Sequential(
      (0): Linear(in_features=17, out_features=64, bias=True)
      (1): Tanh()
      (2): Linear(in_features=64, out_features=64, bias=True)
      (3): Tanh()
    )
  )
  (action_net): Linear(in_features=64, out_features=6, bias=True)
  (value_net): Linear(in_features=64, out_features=1, bias=True)
)
[2K---------------------------------━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m16,032/10,000,000 [0m [ [33m0:00:02[0m < [36m0:24:20[0m , [31m6,840 it/s[0m ]
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | -401     |
| time/              |          |
|    fps             | 5839     |
|    iterations      | 1        |
|    time_elapsed    | 2        |
|    total_timesteps | 16384    |
---------------------------------
[2K------------------------------------------━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m32,304/10,000,000 [0m [ [33m0:00:06[0m < [36m0:32:05[0m , [31m5,179 it/s[0m ]
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -363         |
| time/                   |              |
|    fps                  | 4881         |
|    iterations           | 2            |
|    time_elapsed         | 6            |
|    total_timesteps      | 32768        |
| train/                  |              |
|    approx_kl            | 0.0075209243 |
|    clip_fraction        | 0.0715       |
|    clip_range           | 0.2          |
|    entropy_loss         | -8.52        |
|    explained_variance   | -0.769       |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0222       |
|    n_updates            | 10           |
|    policy_gradient_loss | -0.00741     |
|    std                  | 1            |
|    value_loss           | 0.303        |
------------------------------------------
[2K------------------------------------------;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m48,416/10,000,000 [0m [ [33m0:00:10[0m < [36m0:34:24[0m , [31m4,824 it/s[0m ]
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -342         |
| time/                   |              |
|    fps                  | 4650         |
|    iterations           | 3            |
|    time_elapsed         | 10           |
|    total_timesteps      | 49152        |
| train/                  |              |
|    approx_kl            | 0.0072238985 |
|    clip_fraction        | 0.0682       |
|    clip_range           | 0.2          |
|    entropy_loss         | -8.53        |
|    explained_variance   | -0.0327      |
|    learning_rate        | 0.000299     |
|    loss                 | -0.0665      |
|    n_updates            | 20           |
|    policy_gradient_loss | -0.00746     |
|    std                  | 1            |
|    value_loss           | 0.0938       |
------------------------------------------
[2K------------------------------------------;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m64,944/10,000,000 [0m [ [33m0:00:14[0m < [36m0:35:53[0m , [31m4,615 it/s[0m ]
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -332         |
| time/                   |              |
|    fps                  | 4495         |
|    iterations           | 4            |
|    time_elapsed         | 14           |
|    total_timesteps      | 65536        |
| train/                  |              |
|    approx_kl            | 0.0066059427 |
|    clip_fraction        | 0.0611       |
|    clip_range           | 0.2          |
|    entropy_loss         | -8.53        |
|    explained_variance   | 0.212        |
|    learning_rate        | 0.000299     |
|    loss                 | -0.0446      |
|    n_updates            | 30           |
|    policy_gradient_loss | -0.00704     |
|    std                  | 1            |
|    value_loss           | 0.0964       |
------------------------------------------
[2K------------------------------------------;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m72,880/10,000,000 [0m [ [33m0:00:17[0m < [36m0:37:55[0m , [31m4,365 it/s[0m ]
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -331         |
| time/                   |              |
|    fps                  | 5066         |
|    iterations           | 5            |
|    time_elapsed         | 16           |
|    total_timesteps      | 81920        |
| train/                  |              |
|    approx_kl            | 0.0061594862 |
|    clip_fraction        | 0.0508       |
|    clip_range           | 0.2          |
|    entropy_loss         | -8.52        |
|    explained_variance   | 0.317        |
|    learning_rate        | 0.000298     |
|    loss                 | -0.0562      |
|    n_updates            | 40           |
|    policy_gradient_loss | -0.00661     |
|    std                  | 0.999        |
|    value_loss           | 0.0953       |
------------------------------------------
[2K----------------------------------------38;5;237m╺[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m97,840/10,000,000 [0m [ [33m0:00:22[0m < [36m0:36:32[0m , [31m4,519 it/s[0m ]
| rollout/                |            |
|    ep_len_mean          | 1e+03      |
|    ep_rew_mean          | -322       |
| time/                   |            |
|    fps                  | 4953       |
|    iterations           | 6          |
|    time_elapsed         | 19         |
|    total_timesteps      | 98304      |
| train/                  |            |
|    approx_kl            | 0.00685626 |
|    clip_fraction        | 0.0626     |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.5       |
|    explained_variance   | 0.427      |
|    learning_rate        | 0.000298   |
|    loss                 | -0.0645    |
|    n_updates            | 50         |
|    policy_gradient_loss | -0.00801   |
|    std                  | 0.997      |
|    value_loss           | 0.0928     |
----------------------------------------
[2KEval num_timesteps=102400, episode_reward=-9.51 +/- 0.7638;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m102,384/10,000,000 [0m [ [33m0:00:54[0m < [36m1:36:08[0m , [31m1,716 it/s[0m ]
[2KEpisode length: 1000.00 +/- 0.000m[38;5;237m╺[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m102,384/10,000,000 [0m [ [33m0:00:54[0m < [36m1:36:08[0m , [31m1,716 it/s[0m ]
[2K-----------------------------------------237m╺[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m102,384/10,000,000 [0m [ [33m0:00:54[0m < [36m1:36:08[0m , [31m1,716 it/s[0m ]
| eval/                   |             |
|    mean_ep_length       | 1e+03       |
|    mean_reward          | -9.51       |
| time/                   |             |
|    total_timesteps      | 102400      |
| train/                  |             |
|    approx_kl            | 0.006242899 |
|    clip_fraction        | 0.0571      |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.47       |
|    explained_variance   | 0.467       |
|    learning_rate        | 0.000297    |
|    loss                 | -0.0445     |
|    n_updates            | 60          |
|    policy_gradient_loss | -0.00764    |
|    std                  | 0.992       |
|    value_loss           | 0.0961      |
-----------------------------------------
[2KNew best mean reward!;38;114m━[0m[38;5;237m╺[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m102,384/10,000,000 [0m [ [33m0:00:54[0m < [36m1:36:08[0m , [31m1,716 it/s[0m ]
[2K---------------------------------━[0m[38;5;237m╺[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m114,288/10,000,000 [0m [ [33m0:00:56[0m < [36m3:10:03[0m , [31m867 it/s[0m ]
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | -308     |
| time/              |          |
|    fps             | 2225     |
|    iterations      | 7        |
|    time_elapsed    | 51       |
|    total_timesteps | 114688   |
---------------------------------
[2K-----------------------------------------8;2;249;38;114m╸[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m130,496/10,000,000 [0m [ [33m0:00:59[0m < [36m1:42:06[0m , [31m1,611 it/s[0m ]
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -300        |
| time/                   |             |
|    fps                  | 2371        |
|    iterations           | 8           |
|    time_elapsed         | 55          |
|    total_timesteps      | 131072      |
| train/                  |             |
|    approx_kl            | 0.007226685 |
|    clip_fraction        | 0.0731      |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.45       |
|    explained_variance   | 0.493       |
|    learning_rate        | 0.000297    |
|    loss                 | -0.0439     |
|    n_updates            | 70          |
|    policy_gradient_loss | -0.00891    |
|    std                  | 0.989       |
|    value_loss           | 0.105       |
-----------------------------------------
[2K-----------------------------------------8;2;249;38;114m╸[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m146,656/10,000,000 [0m [ [33m0:01:03[0m < [36m1:18:12[0m , [31m2,100 it/s[0m ]
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -292        |
| time/                   |             |
|    fps                  | 2502        |
|    iterations           | 9           |
|    time_elapsed         | 58          |
|    total_timesteps      | 147456      |
| train/                  |             |
|    approx_kl            | 0.006905284 |
|    clip_fraction        | 0.0602      |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.45       |
|    explained_variance   | 0.5         |
|    learning_rate        | 0.000296    |
|    loss                 | -0.0477     |
|    n_updates            | 80          |
|    policy_gradient_loss | -0.00755    |
|    std                  | 0.99        |
|    value_loss           | 0.0811      |
-----------------------------------------
[2K------------------------------------------;2;249;38;114m╸[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m163,008/10,000,000 [0m [ [33m0:01:07[0m < [36m1:07:05[0m , [31m2,444 it/s[0m ]
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -286         |
| time/                   |              |
|    fps                  | 2613         |
|    iterations           | 10           |
|    time_elapsed         | 62           |
|    total_timesteps      | 163840       |
| train/                  |              |
|    approx_kl            | 0.0063341185 |
|    clip_fraction        | 0.0633       |
|    clip_range           | 0.2          |
|    entropy_loss         | -8.44        |
|    explained_variance   | 0.538        |
|    learning_rate        | 0.000296     |
|    loss                 | -0.0415      |
|    n_updates            | 90           |
|    policy_gradient_loss | -0.0083      |
|    std                  | 0.987        |
|    value_loss           | 0.0775       |
------------------------------------------
[2K-----------------------------------------38;5;237m╺[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m179,328/10,000,000 [0m [ [33m0:01:11[0m < [36m1:01:14[0m , [31m2,673 it/s[0m ]s[0m ]
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -273        |
| time/                   |             |
|    fps                  | 2703        |
|    iterations           | 11          |
|    time_elapsed         | 66          |
|    total_timesteps      | 180224      |
| train/                  |             |
|    approx_kl            | 0.006674771 |
|    clip_fraction        | 0.0617      |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.43       |
|    explained_variance   | 0.533       |
|    learning_rate        | 0.000295    |
|    loss                 | -0.0648     |
|    n_updates            | 100         |
|    policy_gradient_loss | -0.00794    |
|    std                  | 0.986       |
|    value_loss           | 0.0604      |
-----------------------------------------
[2K------------------------------------------8;5;237m╺[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m196,224/10,000,000 [0m [ [33m0:01:15[0m < [36m0:37:33[0m , [31m4,352 it/s[0m ]
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -263         |
| time/                   |              |
|    fps                  | 2756         |
|    iterations           | 12           |
|    time_elapsed         | 71           |
|    total_timesteps      | 196608       |
| train/                  |              |
|    approx_kl            | 0.0065436475 |
|    clip_fraction        | 0.0636       |
|    clip_range           | 0.2          |
|    entropy_loss         | -8.44        |
|    explained_variance   | 0.57         |
|    learning_rate        | 0.000295     |
|    loss                 | -0.0584      |
|    n_updates            | 110          |
|    policy_gradient_loss | -0.00867     |
|    std                  | 0.987        |
|    value_loss           | 0.0618       |
------------------------------------------
[2KEval num_timesteps=204800, episode_reward=-29.97 +/- 1.2038;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m204,784/10,000,000 [0m [ [33m0:01:50[0m < [36m1:54:51[0m , [31m1,422 it/s[0m ]
[2KEpisode length: 1000.00 +/- 0.00[0m[38;5;237m╺[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m204,784/10,000,000 [0m [ [33m0:01:50[0m < [36m1:54:51[0m , [31m1,422 it/s[0m ]
[2K-----------------------------------------;237m╺[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m204,784/10,000,000 [0m [ [33m0:01:50[0m < [36m1:54:51[0m , [31m1,422 it/s[0m ]
| eval/                   |             |
|    mean_ep_length       | 1e+03       |
|    mean_reward          | -30         |
| time/                   |             |
|    total_timesteps      | 204800      |
| train/                  |             |
|    approx_kl            | 0.007249453 |
|    clip_fraction        | 0.0663      |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.42       |
|    explained_variance   | 0.536       |
|    learning_rate        | 0.000294    |
|    loss                 | -0.0569     |
|    n_updates            | 120         |
|    policy_gradient_loss | -0.00898    |
|    std                  | 0.984       |
|    value_loss           | 0.0789      |
-----------------------------------------
[2K---------------------------------━━[0m[38;2;249;38;114m╸[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m212,336/10,000,000 [0m [ [33m0:01:51[0m < [36m5:11:28[0m , [31m524 it/s[0m ]
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | -256     |
| time/              |          |
|    fps             | 2036     |
|    iterations      | 13       |
|    time_elapsed    | 104      |
|    total_timesteps | 212992   |
---------------------------------
[2K------------------------------------------8;2;249;38;114m╸[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m222,608/10,000,000 [0m [ [33m0:01:54[0m < [36m2:37:26[0m , [31m1,035 it/s[0m ]
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -239         |
| time/                   |              |
|    fps                  | 2164         |
|    iterations           | 14           |
|    time_elapsed         | 105          |
|    total_timesteps      | 229376       |
| train/                  |              |
|    approx_kl            | 0.0066828215 |
|    clip_fraction        | 0.0655       |
|    clip_range           | 0.2          |
|    entropy_loss         | -8.41        |
|    explained_variance   | 0.598        |
|    learning_rate        | 0.000294     |
|    loss                 | -0.0735      |
|    n_updates            | 130          |
|    policy_gradient_loss | -0.00926     |
|    std                  | 0.982        |
|    value_loss           | 0.0707       |
------------------------------------------
[2K-----------------------------------------38;2;249;38;114m╸[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m244,928/10,000,000 [0m [ [33m0:01:58[0m < [36m1:27:37[0m , [31m1,856 it/s[0m ]
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -229        |
| time/                   |             |
|    fps                  | 2243        |
|    iterations           | 15          |
|    time_elapsed         | 109         |
|    total_timesteps      | 245760      |
| train/                  |             |
|    approx_kl            | 0.007098171 |
|    clip_fraction        | 0.0703      |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.37       |
|    explained_variance   | 0.588       |
|    learning_rate        | 0.000293    |
|    loss                 | -0.0532     |
|    n_updates            | 140         |
|    policy_gradient_loss | -0.01       |
|    std                  | 0.975       |
|    value_loss           | 0.0759      |
-----------------------------------------
[2K------------------------------------------38;5;237m╺[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m261,632/10,000,000 [0m [ [33m0:02:02[0m < [36m1:13:46[0m , [31m2,201 it/s[0m ]s[0m ]
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -212         |
| time/                   |              |
|    fps                  | 2305         |
|    iterations           | 16           |
|    time_elapsed         | 113          |
|    total_timesteps      | 262144       |
| train/                  |              |
|    approx_kl            | 0.0071017137 |
|    clip_fraction        | 0.0685       |
|    clip_range           | 0.2          |
|    entropy_loss         | -8.33        |
|    explained_variance   | 0.649        |
|    learning_rate        | 0.000293     |
|    loss                 | -0.0582      |
|    n_updates            | 150          |
|    policy_gradient_loss | -0.0102      |
|    std                  | 0.969        |
|    value_loss           | 0.0734       |
------------------------------------------
[2K-----------------------------------------[38;5;237m╺[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m278,064/10,000,000 [0m [ [33m0:02:07[0m < [36m0:37:13[0m , [31m4,355 it/s[0m ]
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -196        |
| time/                   |             |
|    fps                  | 2361        |
|    iterations           | 17          |
|    time_elapsed         | 117         |
|    total_timesteps      | 278528      |
| train/                  |             |
|    approx_kl            | 0.007238714 |
|    clip_fraction        | 0.0747      |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.3        |
|    explained_variance   | 0.599       |
|    learning_rate        | 0.000292    |
|    loss                 | -0.0607     |
|    n_updates            | 160         |
|    policy_gradient_loss | -0.0103     |
|    std                  | 0.965       |
|    value_loss           | 0.0804      |
-----------------------------------------
[2K------------------------------------------38;5;237m╺[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m294,112/10,000,000 [0m [ [33m0:02:10[0m < [36m0:37:26[0m , [31m4,323 it/s[0m ]
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -182         |
| time/                   |              |
|    fps                  | 2420         |
|    iterations           | 18           |
|    time_elapsed         | 121          |
|    total_timesteps      | 294912       |
| train/                  |              |
|    approx_kl            | 0.0064870673 |
|    clip_fraction        | 0.0602       |
|    clip_range           | 0.2          |
|    entropy_loss         | -8.25        |
|    explained_variance   | 0.617        |
|    learning_rate        | 0.000292     |
|    loss                 | -0.0573      |
|    n_updates            | 170          |
|    policy_gradient_loss | -0.00944     |
|    std                  | 0.955        |
|    value_loss           | 0.0773       |
------------------------------------------
[2KEval num_timesteps=307200, episode_reward=-58.81 +/- 1.21m╸[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m307,184/10,000,000 [0m [ [33m0:02:48[0m < [36m1:32:06[0m , [31m1,754 it/s[0m ]
[2KEpisode length: 1000.00 +/- 0.00[0m[38;2;249;38;114m╸[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m307,184/10,000,000 [0m [ [33m0:02:48[0m < [36m1:32:06[0m , [31m1,754 it/s[0m ]
[2K-----------------------------------------2;249;38;114m╸[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m307,184/10,000,000 [0m [ [33m0:02:48[0m < [36m1:32:06[0m , [31m1,754 it/s[0m ]
| eval/                   |             |
|    mean_ep_length       | 1e+03       |
|    mean_reward          | -58.8       |
| time/                   |             |
|    total_timesteps      | 307200      |
| train/                  |             |
|    approx_kl            | 0.007292461 |
|    clip_fraction        | 0.077       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.22       |
|    explained_variance   | 0.603       |
|    learning_rate        | 0.000291    |
|    loss                 | -0.0584     |
|    n_updates            | 180         |
|    policy_gradient_loss | -0.0107     |
|    std                  | 0.951       |
|    value_loss           | 0.0716      |
-----------------------------------------
[2K---------------------------------━━━[0m[38;2;249;38;114m╸[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m310,496/10,000,000 [0m [ [33m0:02:49[0m < [36m14:16:34[0m , [31m189 it/s[0m ]
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | -160     |
| time/              |          |
|    fps             | 1972     |
|    iterations      | 19       |
|    time_elapsed    | 157      |
|    total_timesteps | 311296   |
---------------------------------
[2K-----------------------------------------[38;2;249;38;114m╸[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m327,152/10,000,000 [0m [ [33m0:02:54[0m < [36m3:06:08[0m , [31m866 it/s[0m ]
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -142        |
| time/                   |             |
|    fps                  | 2007        |
|    iterations           | 20          |
|    time_elapsed         | 163         |
|    total_timesteps      | 327680      |
| train/                  |             |
|    approx_kl            | 0.007879729 |
|    clip_fraction        | 0.0847      |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.18       |
|    explained_variance   | 0.591       |
|    learning_rate        | 0.000291    |
|    loss                 | -0.0533     |
|    n_updates            | 190         |
|    policy_gradient_loss | -0.0117     |
|    std                  | 0.945       |
|    value_loss           | 0.0836      |
-----------------------------------------
[2K------------------------------------------38;2;249;38;114m╸[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m342,816/10,000,000 [0m [ [33m0:02:58[0m < [36m2:02:28[0m , [31m1,314 it/s[0m ]
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -122         |
| time/                   |              |
|    fps                  | 2083         |
|    iterations           | 21           |
|    time_elapsed         | 165          |
|    total_timesteps      | 344064       |
| train/                  |              |
|    approx_kl            | 0.0074298773 |
|    clip_fraction        | 0.0796       |
|    clip_range           | 0.2          |
|    entropy_loss         | -8.16        |
|    explained_variance   | 0.58         |
|    learning_rate        | 0.00029      |
|    loss                 | -0.0518      |
|    n_updates            | 200          |
|    policy_gradient_loss | -0.0113      |
|    std                  | 0.943        |
|    value_loss           | 0.0779       |
------------------------------------------
[2K-----------------------------------------[38;5;237m╺[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m359,968/10,000,000 [0m [ [33m0:03:03[0m < [36m0:44:19[0m , [31m3,627 it/s[0m ]m ]
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -101        |
| time/                   |             |
|    fps                  | 2128        |
|    iterations           | 22          |
|    time_elapsed         | 169         |
|    total_timesteps      | 360448      |
| train/                  |             |
|    approx_kl            | 0.008125396 |
|    clip_fraction        | 0.0861      |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.11       |
|    explained_variance   | 0.603       |
|    learning_rate        | 0.00029     |
|    loss                 | -0.0633     |
|    n_updates            | 210         |
|    policy_gradient_loss | -0.0126     |
|    std                  | 0.933       |
|    value_loss           | 0.0652      |
-----------------------------------------
[2K-----------------------------------------[38;5;237m╺[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m376,064/10,000,000 [0m [ [33m0:03:07[0m < [36m0:43:28[0m , [31m3,691 it/s[0m ]
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -85         |
| time/                   |             |
|    fps                  | 2172        |
|    iterations           | 23          |
|    time_elapsed         | 173         |
|    total_timesteps      | 376832      |
| train/                  |             |
|    approx_kl            | 0.008354635 |
|    clip_fraction        | 0.0922      |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.07       |
|    explained_variance   | 0.535       |
|    learning_rate        | 0.000289    |
|    loss                 | -0.0626     |
|    n_updates            | 220         |
|    policy_gradient_loss | -0.0132     |
|    std                  | 0.929       |
|    value_loss           | 0.0674      |
-----------------------------------------
[2K----------------------------------------m[38;2;249;38;114m╸[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m392,560/10,000,000 [0m [ [33m0:03:11[0m < [36m0:42:42[0m , [31m3,751 it/s[0m ]
| rollout/                |            |
|    ep_len_mean          | 1e+03      |
|    ep_rew_mean          | -59.5      |
| time/                   |            |
|    fps                  | 2214       |
|    iterations           | 24         |
|    time_elapsed         | 177        |
|    total_timesteps      | 393216     |
| train/                  |            |
|    approx_kl            | 0.00710796 |
|    clip_fraction        | 0.0728     |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.05      |
|    explained_variance   | 0.609      |
|    learning_rate        | 0.000289   |
|    loss                 | -0.0691    |
|    n_updates            | 230        |
|    policy_gradient_loss | -0.0114    |
|    std                  | 0.926      |
|    value_loss           | 0.0623     |
----------------------------------------
[2KEval num_timesteps=409600, episode_reward=-62.07 +/- 1.164m╸[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m409,584/10,000,000 [0m [ [33m0:03:49[0m < [36m1:59:44[0m , [31m1,335 it/s[0m ]
[2KEpisode length: 1000.00 +/- 0.00━[0m[38;2;249;38;114m╸[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m409,584/10,000,000 [0m [ [33m0:03:49[0m < [36m1:59:44[0m , [31m1,335 it/s[0m ]
[2K-----------------------------------------;2;249;38;114m╸[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m409,584/10,000,000 [0m [ [33m0:03:49[0m < [36m1:59:44[0m , [31m1,335 it/s[0m ]
| eval/                   |             |
|    mean_ep_length       | 1e+03       |
|    mean_reward          | -62.1       |
| time/                   |             |
|    total_timesteps      | 409600      |
| train/                  |             |
|    approx_kl            | 0.008922379 |
|    clip_fraction        | 0.0987      |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.01       |
|    explained_variance   | 0.51        |
|    learning_rate        | 0.000288    |
|    loss                 | -0.0558     |
|    n_updates            | 240         |
|    policy_gradient_loss | -0.0144     |
|    std                  | 0.917       |
|    value_loss           | 0.0643      |
-----------------------------------------
[2K---------------------------------[0m[38;2;249;38;114m╸[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m409,584/10,000,000 [0m [ [33m0:03:49[0m < [36m1:59:44[0m , [31m1,335 it/s[0m ]
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | -33.1    |
| time/              |          |
|    fps             | 1914     |
|    iterations      | 25       |
|    time_elapsed    | 213      |
|    total_timesteps | 409600   |
---------------------------------
[2K-----------------------------------------m[38;5;237m╺[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m425,280/10,000,000 [0m [ [33m0:03:54[0m < [36m3:10:45[0m , [31m837 it/s[0m ]s[0m ]
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | 0.658       |
| time/                   |             |
|    fps                  | 1945        |
|    iterations           | 26          |
|    time_elapsed         | 218         |
|    total_timesteps      | 425984      |
| train/                  |             |
|    approx_kl            | 0.008377422 |
|    clip_fraction        | 0.0994      |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.95       |
|    explained_variance   | 0.471       |
|    learning_rate        | 0.000288    |
|    loss                 | -0.0691     |
|    n_updates            | 250         |
|    policy_gradient_loss | -0.0136     |
|    std                  | 0.908       |
|    value_loss           | 0.063       |
-----------------------------------------
[2K------------------------------------------[38;5;237m╺[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m442,176/10,000,000 [0m [ [33m0:04:00[0m < [36m1:57:54[0m , [31m1,351 it/s[0m ]
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | 26           |
| time/                   |              |
|    fps                  | 1972         |
|    iterations           | 27           |
|    time_elapsed         | 224          |
|    total_timesteps      | 442368       |
| train/                  |              |
|    approx_kl            | 0.0090379445 |
|    clip_fraction        | 0.104        |
|    clip_range           | 0.2          |
|    entropy_loss         | -7.9         |
|    explained_variance   | 0.476        |
|    learning_rate        | 0.000287     |
|    loss                 | -0.0679      |
|    n_updates            | 260          |
|    policy_gradient_loss | -0.0145      |
|    std                  | 0.902        |
|    value_loss           | 0.0653       |
------------------------------------------
[2K-----------------------------------------m[38;5;237m╺[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m446,592/10,000,000 [0m [ [33m0:04:03[0m < [36m1:56:01[0m , [31m1,373 it/s[0m ]
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | 51.4        |
| time/                   |             |
|    fps                  | 2020        |
|    iterations           | 28          |
|    time_elapsed         | 227         |
|    total_timesteps      | 458752      |
| train/                  |             |
|    approx_kl            | 0.008044626 |
|    clip_fraction        | 0.0869      |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.87       |
|    explained_variance   | 0.47        |
|    learning_rate        | 0.000287    |
|    loss                 | -0.0568     |
|    n_updates            | 270         |
|    policy_gradient_loss | -0.0119     |
|    std                  | 0.897       |
|    value_loss           | 0.0658      |
-----------------------------------------
[2K-----------------------------------------m[38;2;249;38;114m╸[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m474,576/10,000,000 [0m [ [33m0:04:10[0m < [36m0:50:20[0m , [31m3,155 it/s[0m ]
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | 92.6        |
| time/                   |             |
|    fps                  | 2045        |
|    iterations           | 29          |
|    time_elapsed         | 232         |
|    total_timesteps      | 475136      |
| train/                  |             |
|    approx_kl            | 0.009463234 |
|    clip_fraction        | 0.103       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.8        |
|    explained_variance   | 0.494       |
|    learning_rate        | 0.000286    |
|    loss                 | -0.0754     |
|    n_updates            | 280         |
|    policy_gradient_loss | -0.0156     |
|    std                  | 0.887       |
|    value_loss           | 0.0554      |
-----------------------------------------
[2K-----------------------------------------m[38;2;249;38;114m╸[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m490,704/10,000,000 [0m [ [33m0:04:14[0m < [36m0:48:16[0m , [31m3,284 it/s[0m ]
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | 129         |
| time/                   |             |
|    fps                  | 2078        |
|    iterations           | 30          |
|    time_elapsed         | 236         |
|    total_timesteps      | 491520      |
| train/                  |             |
|    approx_kl            | 0.007839621 |
|    clip_fraction        | 0.0851      |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.76       |
|    explained_variance   | 0.38        |
|    learning_rate        | 0.000286    |
|    loss                 | -0.0723     |
|    n_updates            | 290         |
|    policy_gradient_loss | -0.0133     |
|    std                  | 0.881       |
|    value_loss           | 0.0544      |
-----------------------------------------
[2K-----------------------------------------m[38;2;249;38;114m╸[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m507,312/10,000,000 [0m [ [33m0:04:18[0m < [36m0:46:16[0m , [31m3,420 it/s[0m ]
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | 168         |
| time/                   |             |
|    fps                  | 2113        |
|    iterations           | 31          |
|    time_elapsed         | 240         |
|    total_timesteps      | 507904      |
| train/                  |             |
|    approx_kl            | 0.008049769 |
|    clip_fraction        | 0.0848      |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.71       |
|    explained_variance   | 0.441       |
|    learning_rate        | 0.000285    |
|    loss                 | -0.0774     |
|    n_updates            | 300         |
|    policy_gradient_loss | -0.0135     |
|    std                  | 0.874       |
|    value_loss           | 0.056       |
-----------------------------------------
[2KTraceback (most recent call last):━━━━[0m[38;2;249;38;114m╸[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m511,984/10,000,000 [0m [ [33m0:04:44[0m < [36m2:03:25[0m , [31m1,281 it/s[0m ]
[2K  File "/mnt/c/Users/yuvra/OneDrive/Desktop/Work/pytorch/RL/PPO/MuJoCo/benchmark/SB3/half-cheetah-sb3.py", line 227, in <module>━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m511,984/10,000,000 [0m [ [33m0:04:44[0m < [36m2:03:25[0m , [31m1,281 it/s[0m ]
    tqdm_callback = TqdmCallback()  # Initialize the tqdm callback for progress bar
[2K  File "/home/yuvrajsingh/anaconda3/envs/mt/lib/python3.11/site-packages/stable_baselines3/ppo/ppo.py", line 311, in learn━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m511,984/10,000,000 [0m [ [33m0:04:44[0m < [36m2:03:25[0m , [31m1,281 it/s[0m ]
    return super().learn(
           ^^^^^^^^^^^^^^
[2K  File "/home/yuvrajsingh/anaconda3/envs/mt/lib/python3.11/site-packages/stable_baselines3/common/on_policy_algorithm.py", line 324, in learn━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m511,984/10,000,000 [0m [ [33m0:04:44[0m < [36m2:03:25[0m , [31m1,281 it/s[0m ]
    continue_training = self.collect_rollouts(self.env, callback, self.rollout_buffer, n_rollout_steps=self.n_steps)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2K  File "/home/yuvrajsingh/anaconda3/envs/mt/lib/python3.11/site-packages/stable_baselines3/common/on_policy_algorithm.py", line 224, in collect_rollouts━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m511,984/10,000,000 [0m [ [33m0:04:44[0m < [36m2:03:25[0m , [31m1,281 it/s[0m ]
    if not callback.on_step():
           ^^^^^^^^^^^^^^^^^^
[2K  File "/home/yuvrajsingh/anaconda3/envs/mt/lib/python3.11/site-packages/stable_baselines3/common/callbacks.py", line 114, in on_step━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m511,984/10,000,000 [0m [ [33m0:04:44[0m < [36m2:03:25[0m , [31m1,281 it/s[0m ]
    return self._on_step()
           ^^^^^^^^^^^^^^^
[2K  File "/home/yuvrajsingh/anaconda3/envs/mt/lib/python3.11/site-packages/stable_baselines3/common/callbacks.py", line 223, in _on_step━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m511,984/10,000,000 [0m [ [33m0:04:44[0m < [36m2:03:25[0m , [31m1,281 it/s[0m ]
    continue_training = callback.on_step() and continue_training
                        ^^^^^^^^^^^^^^^^^^
[2K  File "/home/yuvrajsingh/anaconda3/envs/mt/lib/python3.11/site-packages/stable_baselines3/common/callbacks.py", line 114, in on_step━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m511,984/10,000,000 [0m [ [33m0:04:44[0m < [36m2:03:25[0m , [31m1,281 it/s[0m ]
    return self._on_step()
           ^^^^^^^^^^^^^^^
[2K  File "/home/yuvrajsingh/anaconda3/envs/mt/lib/python3.11/site-packages/stable_baselines3/common/callbacks.py", line 223, in _on_step━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m511,984/10,000,000 [0m [ [33m0:04:44[0m < [36m2:03:25[0m , [31m1,281 it/s[0m ]
    continue_training = callback.on_step() and continue_training
                        ^^^^^^^^^^^^^^^^^^
[2K  File "/home/yuvrajsingh/anaconda3/envs/mt/lib/python3.11/site-packages/stable_baselines3/common/callbacks.py", line 114, in on_step━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m511,984/10,000,000 [0m [ [33m0:04:44[0m < [36m2:03:25[0m , [31m1,281 it/s[0m ]
    return self._on_step()
           ^^^^^^^^^^^^^^^
[2K  File "/home/yuvrajsingh/anaconda3/envs/mt/lib/python3.11/site-packages/stable_baselines3/common/callbacks.py", line 464, in _on_step━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m511,984/10,000,000 [0m [ [33m0:04:44[0m < [36m2:03:25[0m , [31m1,281 it/s[0m ]
    episode_rewards, episode_lengths = evaluate_policy(
                                       ^^^^^^^^^^^^^^^^
[2K  File "/home/yuvrajsingh/anaconda3/envs/mt/lib/python3.11/site-packages/stable_baselines3/common/evaluation.py", line 94, in evaluate_policy━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m511,984/10,000,000 [0m [ [33m0:04:44[0m < [36m2:03:25[0m , [31m1,281 it/s[0m ]
    new_observations, rewards, dones, infos = env.step(actions)
                                              ^^^^^^^^^^^^^^^^^
[2K  File "/home/yuvrajsingh/anaconda3/envs/mt/lib/python3.11/site-packages/stable_baselines3/common/vec_env/base_vec_env.py", line 222, in step━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m511,984/10,000,000 [0m [ [33m0:04:44[0m < [36m2:03:25[0m , [31m1,281 it/s[0m ]
    return self.step_wait()
           ^^^^^^^^^^^^^^^^
[2K  File "/home/yuvrajsingh/anaconda3/envs/mt/lib/python3.11/site-packages/stable_baselines3/common/vec_env/vec_normalize.py", line 181, in step_wait━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m511,984/10,000,000 [0m [ [33m0:04:44[0m < [36m2:03:25[0m , [31m1,281 it/s[0m ]
    obs, rewards, dones, infos = self.venv.step_wait()
                                 ^^^^^^^^^^^^^^^^^^^^^
[2K  File "/home/yuvrajsingh/anaconda3/envs/mt/lib/python3.11/site-packages/stable_baselines3/common/vec_env/subproc_vec_env.py", line 137, in step_wait━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m511,984/10,000,000 [0m [ [33m0:04:44[0m < [36m2:03:25[0m , [31m1,281 it/s[0m ]
    results = [remote.recv() for remote in self.remotes]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2K  File "/home/yuvrajsingh/anaconda3/envs/mt/lib/python3.11/site-packages/stable_baselines3/common/vec_env/subproc_vec_env.py", line 137, in <listcomp>━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m511,984/10,000,000 [0m [ [33m0:04:44[0m < [36m2:03:25[0m , [31m1,281 it/s[0m ]
    results = [remote.recv() for remote in self.remotes]
               ^^^^^^^^^^^^^
[2K  File "/home/yuvrajsingh/anaconda3/envs/mt/lib/python3.11/multiprocessing/connection.py", line 250, in recv━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m511,984/10,000,000 [0m [ [33m0:04:44[0m < [36m2:03:25[0m , [31m1,281 it/s[0m ]
    buf = self._recv_bytes()
          ^^^^^^^^^^^^^^^^^^
[2K  File "/home/yuvrajsingh/anaconda3/envs/mt/lib/python3.11/multiprocessing/connection.py", line 430, in _recv_bytes━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m511,984/10,000,000 [0m [ [33m0:04:44[0m < [36m2:03:25[0m , [31m1,281 it/s[0m ]
    buf = self._recv(4)
          ^^^^^^^^^^^^^
[2K  File "/home/yuvrajsingh/anaconda3/envs/mt/lib/python3.11/multiprocessing/connection.py", line 395, in _recv━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m511,984/10,000,000 [0m [ [33m0:04:44[0m < [36m2:03:25[0m , [31m1,281 it/s[0m ]
    chunk = read(handle, remaining)
            ^^^^^^^^^^^^^^^^^^^^^^^
[2KKeyboardInterrupt;249;38;114m━━━━━[0m[38;2;249;38;114m╸[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m511,984/10,000,000 [0m [ [33m0:04:44[0m < [36m2:03:25[0m , [31m1,281 it/s[0m ]
[2KException ignored in atexit callback: <function _start_and_connect_service.<locals>.teardown_atexit at 0x7f6c2b1151c0>━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m511,984/10,000,000 [0m [ [33m0:04:44[0m < [36m2:03:25[0m , [31m1,281 it/s[0m ]
[2KTraceback (most recent call last):[0m[38;2;249;38;114m╸[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m511,984/10,000,000 [0m [ [33m0:04:44[0m < [36m2:03:25[0m , [31m1,281 it/s[0m ]
[2K  File "/home/yuvrajsingh/anaconda3/envs/mt/lib/python3.11/site-packages/wandb/sdk/lib/service_connection.py", line 94, in teardown_atexit━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m511,984/10,000,000 [0m [ [33m0:04:44[0m < [36m2:03:25[0m , [31m1,281 it/s[0m ]
[2K    conn.teardown(hooks.exit_code)[0m[38;2;249;38;114m╸[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m511,984/10,000,000 [0m [ [33m0:04:44[0m < [36m2:03:25[0m , [31m1,281 it/s[0m ]
[2K  File "/home/yuvrajsingh/anaconda3/envs/mt/lib/python3.11/site-packages/wandb/sdk/lib/service_connection.py", line 226, in teardown━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m511,984/10,000,000 [0m [ [33m0:04:44[0m < [36m2:03:25[0m , [31m1,281 it/s[0m ]
[2K    self._router.join()8;114m━━━━━[0m[38;2;249;38;114m╸[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m511,984/10,000,000 [0m [ [33m0:04:44[0m < [36m2:03:25[0m , [31m1,281 it/s[0m ]
[2K  File "/home/yuvrajsingh/anaconda3/envs/mt/lib/python3.11/site-packages/wandb/sdk/interface/router.py", line 75, in join━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m511,984/10,000,000 [0m [ [33m0:04:44[0m < [36m2:03:25[0m , [31m1,281 it/s[0m ]
[2K    self._thread.join()8;114m━━━━━[0m[38;2;249;38;114m╸[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m511,984/10,000,000 [0m [ [33m0:04:44[0m < [36m2:03:25[0m , [31m1,281 it/s[0m ]
[2K  File "/home/yuvrajsingh/anaconda3/envs/mt/lib/python3.11/threading.py", line 1119, in join━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m511,984/10,000,000 [0m [ [33m0:04:44[0m < [36m2:03:25[0m , [31m1,281 it/s[0m ]
[2K    self._wait_for_tstate_lock()━━[0m[38;2;249;38;114m╸[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m511,984/10,000,000 [0m [ [33m0:04:44[0m < [36m2:03:25[0m , [31m1,281 it/s[0m ]
[2K  File "/home/yuvrajsingh/anaconda3/envs/mt/lib/python3.11/threading.py", line 1139, in _wait_for_tstate_lock━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m511,984/10,000,000 [0m [ [33m0:04:44[0m < [36m2:03:25[0m , [31m1,281 it/s[0m ]
[2K    if lock.acquire(block, timeout):0m[38;2;249;38;114m╸[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m511,984/10,000,000 [0m [ [33m0:04:44[0m < [36m2:03:25[0m , [31m1,281 it/s[0m ]
[2K       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^[0m[38;2;249;38;114m╸[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m511,984/10,000,000 [0m [ [33m0:04:44[0m < [36m2:03:25[0m , [31m1,281 it/s[0m ]
[2KKeyboardInterrupt: 49;38;114m━━━━━[0m[38;2;249;38;114m╸[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m511,984/10,000,000 [0m [ [33m0:04:44[0m < [36m2:03:25[0m , [31m1,281 it/s[0m ]
[2K[35m   5%[0m [38;2;249;38;114m━━━━━[0m[38;2;249;38;114m╸[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m511,984/10,000,000 [0m [ [33m0:04:44[0m < [36m2:03:25[0m , [31m1,281 it/s[0m ]
