Using cuda device
/home/yuvrajsingh/anaconda3/envs/mt/lib/python3.11/site-packages/stable_baselines3/common/on_policy_algorithm.py:150: UserWarning: You are trying to run PPO on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.
  warnings.warn(
ActorCriticPolicy(
  (features_extractor): FlattenExtractor(
    (flatten): Flatten(start_dim=1, end_dim=-1)
  )
  (pi_features_extractor): FlattenExtractor(
    (flatten): Flatten(start_dim=1, end_dim=-1)
  )
  (vf_features_extractor): FlattenExtractor(
    (flatten): Flatten(start_dim=1, end_dim=-1)
  )
  (mlp_extractor): MlpExtractor(
    (policy_net): Sequential(
      (0): Linear(in_features=17, out_features=64, bias=True)
      (1): Tanh()
      (2): Linear(in_features=64, out_features=64, bias=True)
      (3): Tanh()
    )
    (value_net): Sequential(
      (0): Linear(in_features=17, out_features=64, bias=True)
      (1): Tanh()
      (2): Linear(in_features=64, out_features=64, bias=True)
      (3): Tanh()
    )
  )
  (action_net): Linear(in_features=64, out_features=6, bias=True)
  (value_net): Linear(in_features=64, out_features=1, bias=True)
)
Logging to runs/yen6uj00/PPO_1
[2K---------------------------------━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m16,144/10,000,000 [0m [ [33m0:00:03[0m < [36m0:29:43[0m , [31m5,602 it/s[0m ]
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | -401     |
| time/              |          |
|    fps             | 4522     |
|    iterations      | 1        |
|    time_elapsed    | 3        |
|    total_timesteps | 16384    |
---------------------------------
[2K------------------------------------------━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m32,128/10,000,000 [0m [ [33m0:00:08[0m < [36m0:40:41[0m , [31m4,084 it/s[0m ]
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -363         |
| time/                   |              |
|    fps                  | 3776         |
|    iterations           | 2            |
|    time_elapsed         | 8            |
|    total_timesteps      | 32768        |
| train/                  |              |
|    approx_kl            | 0.0075209243 |
|    clip_fraction        | 0.0715       |
|    clip_range           | 0.2          |
|    entropy_loss         | -8.52        |
|    explained_variance   | -0.769       |
|    learning_rate        | 0.0003       |
|    loss                 | 0.0222       |
|    n_updates            | 10           |
|    policy_gradient_loss | -0.00741     |
|    std                  | 1            |
|    value_loss           | 0.303        |
------------------------------------------
[2K------------------------------------------;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m48,272/10,000,000 [0m [ [33m0:00:12[0m < [36m0:42:12[0m , [31m3,931 it/s[0m ]
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -342         |
| time/                   |              |
|    fps                  | 3749         |
|    iterations           | 3            |
|    time_elapsed         | 13           |
|    total_timesteps      | 49152        |
| train/                  |              |
|    approx_kl            | 0.0072238985 |
|    clip_fraction        | 0.0682       |
|    clip_range           | 0.2          |
|    entropy_loss         | -8.53        |
|    explained_variance   | -0.0327      |
|    learning_rate        | 0.000299     |
|    loss                 | -0.0665      |
|    n_updates            | 20           |
|    policy_gradient_loss | -0.00746     |
|    std                  | 1            |
|    value_loss           | 0.0938       |
------------------------------------------
[2K------------------------------------------;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m65,296/10,000,000 [0m [ [33m0:00:17[0m < [36m0:42:54[0m , [31m3,860 it/s[0m ]
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -332         |
| time/                   |              |
|    fps                  | 3710         |
|    iterations           | 4            |
|    time_elapsed         | 17           |
|    total_timesteps      | 65536        |
| train/                  |              |
|    approx_kl            | 0.0066059427 |
|    clip_fraction        | 0.0611       |
|    clip_range           | 0.2          |
|    entropy_loss         | -8.53        |
|    explained_variance   | 0.212        |
|    learning_rate        | 0.000299     |
|    loss                 | -0.0446      |
|    n_updates            | 30           |
|    policy_gradient_loss | -0.00704     |
|    std                  | 1            |
|    value_loss           | 0.0964       |
------------------------------------------
[2K------------------------------------------;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m80,880/10,000,000 [0m [ [33m0:00:22[0m < [36m0:43:38[0m , [31m3,790 it/s[0m ]
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -331         |
| time/                   |              |
|    fps                  | 3689         |
|    iterations           | 5            |
|    time_elapsed         | 22           |
|    total_timesteps      | 81920        |
| train/                  |              |
|    approx_kl            | 0.0061594862 |
|    clip_fraction        | 0.0508       |
|    clip_range           | 0.2          |
|    entropy_loss         | -8.52        |
|    explained_variance   | 0.317        |
|    learning_rate        | 0.000298     |
|    loss                 | -0.0562      |
|    n_updates            | 40           |
|    policy_gradient_loss | -0.00661     |
|    std                  | 0.999        |
|    value_loss           | 0.0953       |
------------------------------------------
[2K----------------------------------------38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m83,616/10,000,000 [0m [ [33m0:00:24[0m < [36m0:46:24[0m , [31m3,563 it/s[0m ]
| rollout/                |            |
|    ep_len_mean          | 1e+03      |
|    ep_rew_mean          | -322       |
| time/                   |            |
|    fps                  | 4101       |
|    iterations           | 6          |
|    time_elapsed         | 23         |
|    total_timesteps      | 98304      |
| train/                  |            |
|    approx_kl            | 0.00685626 |
|    clip_fraction        | 0.0626     |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.5       |
|    explained_variance   | 0.427      |
|    learning_rate        | 0.000298   |
|    loss                 | -0.0645    |
|    n_updates            | 50         |
|    policy_gradient_loss | -0.00801   |
|    std                  | 0.997      |
|    value_loss           | 0.0928     |
----------------------------------------
[2KEval num_timesteps=102400, episode_reward=-9.51 +/- 0.7638;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m102,384/10,000,000 [0m [ [33m0:01:02[0m < [36m1:25:20[0m , [31m1,933 it/s[0m ]
[2KEpisode length: 1000.00 +/- 0.000m[38;5;237m╺[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m102,384/10,000,000 [0m [ [33m0:01:02[0m < [36m1:25:20[0m , [31m1,933 it/s[0m ]
[2K-----------------------------------------237m╺[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m102,384/10,000,000 [0m [ [33m0:01:02[0m < [36m1:25:20[0m , [31m1,933 it/s[0m ]
| eval/                   |             |
|    mean_ep_length       | 1e+03       |
|    mean_reward          | -9.51       |
| time/                   |             |
|    total_timesteps      | 102400      |
| train/                  |             |
|    approx_kl            | 0.006242899 |
|    clip_fraction        | 0.0571      |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.47       |
|    explained_variance   | 0.467       |
|    learning_rate        | 0.000297    |
|    loss                 | -0.0445     |
|    n_updates            | 60          |
|    policy_gradient_loss | -0.00764    |
|    std                  | 0.992       |
|    value_loss           | 0.0961      |
-----------------------------------------
[2KNew best mean reward!;249;38;114m━[0m[38;5;237m╺[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m102,384/10,000,000 [0m [ [33m0:01:02[0m < [36m1:25:20[0m , [31m1,933 it/s[0m ]
[2K---------------------------------━[0m[38;5;237m╺[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m114,480/10,000,000 [0m [ [33m0:01:04[0m < [36m5:05:00[0m , [31m540 it/s[0m ]
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | -308     |
| time/              |          |
|    fps             | 1906     |
|    iterations      | 7        |
|    time_elapsed    | 60       |
|    total_timesteps | 114688   |
---------------------------------
[2K-----------------------------------------8;2;249;38;114m╸[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m130,608/10,000,000 [0m [ [33m0:01:08[0m < [36m2:33:32[0m , [31m1,071 it/s[0m ]
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -300        |
| time/                   |             |
|    fps                  | 2043        |
|    iterations           | 8           |
|    time_elapsed         | 64          |
|    total_timesteps      | 131072      |
| train/                  |             |
|    approx_kl            | 0.007226685 |
|    clip_fraction        | 0.0731      |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.45       |
|    explained_variance   | 0.493       |
|    learning_rate        | 0.000297    |
|    loss                 | -0.0439     |
|    n_updates            | 70          |
|    policy_gradient_loss | -0.00891    |
|    std                  | 0.989       |
|    value_loss           | 0.105       |
-----------------------------------------
[2K-----------------------------------------8;2;249;38;114m╸[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m146,896/10,000,000 [0m [ [33m0:01:12[0m < [36m0:36:23[0m , [31m4,515 it/s[0m ]
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -292        |
| time/                   |             |
|    fps                  | 2162        |
|    iterations           | 9           |
|    time_elapsed         | 68          |
|    total_timesteps      | 147456      |
| train/                  |             |
|    approx_kl            | 0.006905284 |
|    clip_fraction        | 0.0602      |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.45       |
|    explained_variance   | 0.5         |
|    learning_rate        | 0.000296    |
|    loss                 | -0.0477     |
|    n_updates            | 80          |
|    policy_gradient_loss | -0.00755    |
|    std                  | 0.99        |
|    value_loss           | 0.0811      |
-----------------------------------------
[2K------------------------------------------;2;249;38;114m╸[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m162,992/10,000,000 [0m [ [33m0:01:16[0m < [36m0:37:13[0m , [31m4,406 it/s[0m ]
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -286         |
| time/                   |              |
|    fps                  | 2271         |
|    iterations           | 10           |
|    time_elapsed         | 72           |
|    total_timesteps      | 163840       |
| train/                  |              |
|    approx_kl            | 0.0063341185 |
|    clip_fraction        | 0.0633       |
|    clip_range           | 0.2          |
|    entropy_loss         | -8.44        |
|    explained_variance   | 0.538        |
|    learning_rate        | 0.000296     |
|    loss                 | -0.0415      |
|    n_updates            | 90           |
|    policy_gradient_loss | -0.0083      |
|    std                  | 0.987        |
|    value_loss           | 0.0775       |
------------------------------------------
[2K-----------------------------------------38;5;237m╺[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m179,024/10,000,000 [0m [ [33m0:01:20[0m < [36m0:37:37[0m , [31m4,353 it/s[0m ]s[0m ]
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -273        |
| time/                   |             |
|    fps                  | 2370        |
|    iterations           | 11          |
|    time_elapsed         | 76          |
|    total_timesteps      | 180224      |
| train/                  |             |
|    approx_kl            | 0.006674771 |
|    clip_fraction        | 0.0617      |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.43       |
|    explained_variance   | 0.533       |
|    learning_rate        | 0.000295    |
|    loss                 | -0.0648     |
|    n_updates            | 100         |
|    policy_gradient_loss | -0.00794    |
|    std                  | 0.986       |
|    value_loss           | 0.0604      |
-----------------------------------------
[2K------------------------------------------8;5;237m╺[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m195,840/10,000,000 [0m [ [33m0:01:24[0m < [36m0:37:57[0m , [31m4,307 it/s[0m ]
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -263         |
| time/                   |              |
|    fps                  | 2455         |
|    iterations           | 12           |
|    time_elapsed         | 80           |
|    total_timesteps      | 196608       |
| train/                  |              |
|    approx_kl            | 0.0065436475 |
|    clip_fraction        | 0.0636       |
|    clip_range           | 0.2          |
|    entropy_loss         | -8.44        |
|    explained_variance   | 0.57         |
|    learning_rate        | 0.000295     |
|    loss                 | -0.0584      |
|    n_updates            | 110          |
|    policy_gradient_loss | -0.00867     |
|    std                  | 0.987        |
|    value_loss           | 0.0618       |
------------------------------------------
[2KEval num_timesteps=204800, episode_reward=-29.97 +/- 1.2038;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m204,784/10,000,000 [0m [ [33m0:02:00[0m < [36m1:55:25[0m , [31m1,415 it/s[0m ]
[2KEpisode length: 1000.00 +/- 0.00[0m[38;5;237m╺[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m204,784/10,000,000 [0m [ [33m0:02:00[0m < [36m1:55:25[0m , [31m1,415 it/s[0m ]
[2K-----------------------------------------;237m╺[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m204,784/10,000,000 [0m [ [33m0:02:00[0m < [36m1:55:25[0m , [31m1,415 it/s[0m ]
| eval/                   |             |
|    mean_ep_length       | 1e+03       |
|    mean_reward          | -30         |
| time/                   |             |
|    total_timesteps      | 204800      |
| train/                  |             |
|    approx_kl            | 0.007249453 |
|    clip_fraction        | 0.0663      |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.42       |
|    explained_variance   | 0.536       |
|    learning_rate        | 0.000294    |
|    loss                 | -0.0569     |
|    n_updates            | 120         |
|    policy_gradient_loss | -0.00898    |
|    std                  | 0.984       |
|    value_loss           | 0.0789      |
-----------------------------------------
[2K---------------------------------0m[38;5;237m╺[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m204,784/10,000,000 [0m [ [33m0:02:00[0m < [36m1:55:25[0m , [31m1,415 it/s[0m ]
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | -256     |
| time/              |          |
|    fps             | 1871     |
|    iterations      | 13       |
|    time_elapsed    | 113      |
|    total_timesteps | 212992   |
---------------------------------
[2K------------------------------------------8;2;249;38;114m╸[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m228,832/10,000,000 [0m [ [33m0:02:07[0m < [36m2:16:53[0m , [31m1,190 it/s[0m ]
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -239         |
| time/                   |              |
|    fps                  | 1942         |
|    iterations           | 14           |
|    time_elapsed         | 118          |
|    total_timesteps      | 229376       |
| train/                  |              |
|    approx_kl            | 0.0066828215 |
|    clip_fraction        | 0.0655       |
|    clip_range           | 0.2          |
|    entropy_loss         | -8.41        |
|    explained_variance   | 0.598        |
|    learning_rate        | 0.000294     |
|    loss                 | -0.0735      |
|    n_updates            | 130          |
|    policy_gradient_loss | -0.00926     |
|    std                  | 0.982        |
|    value_loss           | 0.0707       |
------------------------------------------
[2K-----------------------------------------38;2;249;38;114m╸[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m245,584/10,000,000 [0m [ [33m0:02:11[0m < [36m1:36:07[0m , [31m1,691 it/s[0m ]
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -229        |
| time/                   |             |
|    fps                  | 2016        |
|    iterations           | 15          |
|    time_elapsed         | 121         |
|    total_timesteps      | 245760      |
| train/                  |             |
|    approx_kl            | 0.007098171 |
|    clip_fraction        | 0.0703      |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.37       |
|    explained_variance   | 0.588       |
|    learning_rate        | 0.000293    |
|    loss                 | -0.0532     |
|    n_updates            | 140         |
|    policy_gradient_loss | -0.01       |
|    std                  | 0.975       |
|    value_loss           | 0.0759      |
-----------------------------------------
[2K------------------------------------------38;5;237m╺[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m260,992/10,000,000 [0m [ [33m0:02:14[0m < [36m1:20:32[0m , [31m2,016 it/s[0m ]s[0m ]
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -212         |
| time/                   |              |
|    fps                  | 2083         |
|    iterations           | 16           |
|    time_elapsed         | 125          |
|    total_timesteps      | 262144       |
| train/                  |              |
|    approx_kl            | 0.0071017137 |
|    clip_fraction        | 0.0685       |
|    clip_range           | 0.2          |
|    entropy_loss         | -8.33        |
|    explained_variance   | 0.649        |
|    learning_rate        | 0.000293     |
|    loss                 | -0.0582      |
|    n_updates            | 150          |
|    policy_gradient_loss | -0.0102      |
|    std                  | 0.969        |
|    value_loss           | 0.0734       |
------------------------------------------
[2K-----------------------------------------[38;5;237m╺[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m277,616/10,000,000 [0m [ [33m0:02:18[0m < [36m0:37:43[0m , [31m4,297 it/s[0m ]
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -196        |
| time/                   |             |
|    fps                  | 2149        |
|    iterations           | 17          |
|    time_elapsed         | 129         |
|    total_timesteps      | 278528      |
| train/                  |             |
|    approx_kl            | 0.007238714 |
|    clip_fraction        | 0.0747      |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.3        |
|    explained_variance   | 0.599       |
|    learning_rate        | 0.000292    |
|    loss                 | -0.0607     |
|    n_updates            | 160         |
|    policy_gradient_loss | -0.0103     |
|    std                  | 0.965       |
|    value_loss           | 0.0804      |
-----------------------------------------
[2K------------------------------------------38;5;237m╺[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m293,568/10,000,000 [0m [ [33m0:02:22[0m < [36m0:37:42[0m , [31m4,292 it/s[0m ]
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -182         |
| time/                   |              |
|    fps                  | 2210         |
|    iterations           | 18           |
|    time_elapsed         | 133          |
|    total_timesteps      | 294912       |
| train/                  |              |
|    approx_kl            | 0.0064870673 |
|    clip_fraction        | 0.0602       |
|    clip_range           | 0.2          |
|    entropy_loss         | -8.25        |
|    explained_variance   | 0.617        |
|    learning_rate        | 0.000292     |
|    loss                 | -0.0573      |
|    n_updates            | 170          |
|    policy_gradient_loss | -0.00944     |
|    std                  | 0.955        |
|    value_loss           | 0.0773       |
------------------------------------------
[2KEval num_timesteps=307200, episode_reward=-58.81 +/- 1.21m╸[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m307,184/10,000,000 [0m [ [33m0:02:58[0m < [36m0:34:50[0m , [31m4,639 it/s[0m ]
[2KEpisode length: 1000.00 +/- 0.00[0m[38;2;249;38;114m╸[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m307,184/10,000,000 [0m [ [33m0:02:58[0m < [36m0:34:50[0m , [31m4,639 it/s[0m ]
[2K-----------------------------------------2;249;38;114m╸[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m307,184/10,000,000 [0m [ [33m0:02:58[0m < [36m0:34:50[0m , [31m4,639 it/s[0m ]
| eval/                   |             |
|    mean_ep_length       | 1e+03       |
|    mean_reward          | -58.8       |
| time/                   |             |
|    total_timesteps      | 307200      |
| train/                  |             |
|    approx_kl            | 0.007292461 |
|    clip_fraction        | 0.077       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.22       |
|    explained_variance   | 0.603       |
|    learning_rate        | 0.000291    |
|    loss                 | -0.0584     |
|    n_updates            | 180         |
|    policy_gradient_loss | -0.0107     |
|    std                  | 0.951       |
|    value_loss           | 0.0716      |
-----------------------------------------
[2K---------------------------------━━━[0m[38;2;249;38;114m╸[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m310,688/10,000,000 [0m [ [33m0:02:59[0m < [36m0:23:44[0m , [31m6,806 it/s[0m ]
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | -160     |
| time/              |          |
|    fps             | 1851     |
|    iterations      | 19       |
|    time_elapsed    | 168      |
|    total_timesteps | 311296   |
---------------------------------
[2K-----------------------------------------[38;2;249;38;114m╸[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m327,232/10,000,000 [0m [ [33m0:03:03[0m < [36m0:36:10[0m , [31m4,459 it/s[0m ]
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -142        |
| time/                   |             |
|    fps                  | 1904        |
|    iterations           | 20          |
|    time_elapsed         | 172         |
|    total_timesteps      | 327680      |
| train/                  |             |
|    approx_kl            | 0.007879729 |
|    clip_fraction        | 0.0847      |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.18       |
|    explained_variance   | 0.591       |
|    learning_rate        | 0.000291    |
|    loss                 | -0.0533     |
|    n_updates            | 190         |
|    policy_gradient_loss | -0.0117     |
|    std                  | 0.945       |
|    value_loss           | 0.0836      |
-----------------------------------------
[2K------------------------------------------38;2;249;38;114m╸[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m330,128/10,000,000 [0m [ [33m0:03:05[0m < [36m0:45:38[0m , [31m3,532 it/s[0m ]
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -122         |
| time/                   |              |
|    fps                  | 1981         |
|    iterations           | 21           |
|    time_elapsed         | 173          |
|    total_timesteps      | 344064       |
| train/                  |              |
|    approx_kl            | 0.0074298773 |
|    clip_fraction        | 0.0796       |
|    clip_range           | 0.2          |
|    entropy_loss         | -8.16        |
|    explained_variance   | 0.58         |
|    learning_rate        | 0.00029      |
|    loss                 | -0.0518      |
|    n_updates            | 200          |
|    policy_gradient_loss | -0.0113      |
|    std                  | 0.943        |
|    value_loss           | 0.0779       |
------------------------------------------
[2K-----------------------------------------[38;5;237m╺[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m359,264/10,000,000 [0m [ [33m0:03:11[0m < [36m0:38:04[0m , [31m4,221 it/s[0m ]s[0m ]
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -101        |
| time/                   |             |
|    fps                  | 2028        |
|    iterations           | 22          |
|    time_elapsed         | 177         |
|    total_timesteps      | 360448      |
| train/                  |             |
|    approx_kl            | 0.008125396 |
|    clip_fraction        | 0.0861      |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.11       |
|    explained_variance   | 0.603       |
|    learning_rate        | 0.00029     |
|    loss                 | -0.0633     |
|    n_updates            | 210         |
|    policy_gradient_loss | -0.0126     |
|    std                  | 0.933       |
|    value_loss           | 0.0652      |
-----------------------------------------
[2K-----------------------------------------[38;5;237m╺[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m375,888/10,000,000 [0m [ [33m0:03:15[0m < [36m0:38:54[0m , [31m4,125 it/s[0m ]
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -85         |
| time/                   |             |
|    fps                  | 2070        |
|    iterations           | 23          |
|    time_elapsed         | 181         |
|    total_timesteps      | 376832      |
| train/                  |             |
|    approx_kl            | 0.008354635 |
|    clip_fraction        | 0.0922      |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.07       |
|    explained_variance   | 0.535       |
|    learning_rate        | 0.000289    |
|    loss                 | -0.0626     |
|    n_updates            | 220         |
|    policy_gradient_loss | -0.0132     |
|    std                  | 0.929       |
|    value_loss           | 0.0674      |
-----------------------------------------
[2K----------------------------------------m[38;2;249;38;114m╸[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m392,560/10,000,000 [0m [ [33m0:03:20[0m < [36m0:39:52[0m , [31m4,017 it/s[0m ]
| rollout/                |            |
|    ep_len_mean          | 1e+03      |
|    ep_rew_mean          | -59.5      |
| time/                   |            |
|    fps                  | 2107       |
|    iterations           | 24         |
|    time_elapsed         | 186        |
|    total_timesteps      | 393216     |
| train/                  |            |
|    approx_kl            | 0.00710796 |
|    clip_fraction        | 0.0728     |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.05      |
|    explained_variance   | 0.609      |
|    learning_rate        | 0.000289   |
|    loss                 | -0.0691    |
|    n_updates            | 230        |
|    policy_gradient_loss | -0.0114    |
|    std                  | 0.926      |
|    value_loss           | 0.0623     |
----------------------------------------
[2KEval num_timesteps=409600, episode_reward=-62.07 +/- 1.164m╸[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m409,584/10,000,000 [0m [ [33m0:03:58[0m < [36m2:20:37[0m , [31m1,137 it/s[0m ]
[2KEpisode length: 1000.00 +/- 0.00━[0m[38;2;249;38;114m╸[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m409,584/10,000,000 [0m [ [33m0:03:58[0m < [36m2:20:37[0m , [31m1,137 it/s[0m ]
[2K-----------------------------------------;2;249;38;114m╸[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m409,584/10,000,000 [0m [ [33m0:03:58[0m < [36m2:20:37[0m , [31m1,137 it/s[0m ]
| eval/                   |             |
|    mean_ep_length       | 1e+03       |
|    mean_reward          | -62.1       |
| time/                   |             |
|    total_timesteps      | 409600      |
| train/                  |             |
|    approx_kl            | 0.008922379 |
|    clip_fraction        | 0.0987      |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.01       |
|    explained_variance   | 0.51        |
|    learning_rate        | 0.000288    |
|    loss                 | -0.0558     |
|    n_updates            | 240         |
|    policy_gradient_loss | -0.0144     |
|    std                  | 0.917       |
|    value_loss           | 0.0643      |
-----------------------------------------
[2K---------------------------------━━━━[0m[38;2;249;38;114m╸[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m409,584/10,000,000 [0m [ [33m0:03:58[0m < [36m2:20:37[0m , [31m1,137 it/s[0m ]
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | -33.1    |
| time/              |          |
|    fps             | 1839     |
|    iterations      | 25       |
|    time_elapsed    | 222      |
|    total_timesteps | 409600   |
---------------------------------
[2K-----------------------------------------m[38;5;237m╺[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m425,936/10,000,000 [0m [ [33m0:04:02[0m < [36m2:42:42[0m , [31m981 it/s[0m ]s[0m ]
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | 0.658       |
| time/                   |             |
|    fps                  | 1878        |
|    iterations           | 26          |
|    time_elapsed         | 226         |
|    total_timesteps      | 425984      |
| train/                  |             |
|    approx_kl            | 0.008377422 |
|    clip_fraction        | 0.0994      |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.95       |
|    explained_variance   | 0.471       |
|    learning_rate        | 0.000288    |
|    loss                 | -0.0691     |
|    n_updates            | 250         |
|    policy_gradient_loss | -0.0136     |
|    std                  | 0.908       |
|    value_loss           | 0.063       |
-----------------------------------------
[2K------------------------------------------[38;5;237m╺[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m442,048/10,000,000 [0m [ [33m0:04:06[0m < [36m1:42:27[0m , [31m1,555 it/s[0m ]s[0m ]
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | 26           |
| time/                   |              |
|    fps                  | 1914         |
|    iterations           | 27           |
|    time_elapsed         | 231          |
|    total_timesteps      | 442368       |
| train/                  |              |
|    approx_kl            | 0.0090379445 |
|    clip_fraction        | 0.104        |
|    clip_range           | 0.2          |
|    entropy_loss         | -7.9         |
|    explained_variance   | 0.476        |
|    learning_rate        | 0.000287     |
|    loss                 | -0.0679      |
|    n_updates            | 260          |
|    policy_gradient_loss | -0.0145      |
|    std                  | 0.902        |
|    value_loss           | 0.0653       |
------------------------------------------
[2K-----------------------------------------m[38;5;237m╺[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m449,856/10,000,000 [0m [ [33m0:04:09[0m < [36m1:33:57[0m , [31m1,694 it/s[0m ]
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | 51.4        |
| time/                   |             |
|    fps                  | 1969        |
|    iterations           | 28          |
|    time_elapsed         | 232         |
|    total_timesteps      | 458752      |
| train/                  |             |
|    approx_kl            | 0.008044626 |
|    clip_fraction        | 0.0869      |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.87       |
|    explained_variance   | 0.47        |
|    learning_rate        | 0.000287    |
|    loss                 | -0.0568     |
|    n_updates            | 270         |
|    policy_gradient_loss | -0.0119     |
|    std                  | 0.897       |
|    value_loss           | 0.0658      |
-----------------------------------------
[2K-----------------------------------------m[38;2;249;38;114m╸[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m474,288/10,000,000 [0m [ [33m0:04:16[0m < [36m1:13:21[0m , [31m2,165 it/s[0m ]
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | 92.6        |
| time/                   |             |
|    fps                  | 1997        |
|    iterations           | 29          |
|    time_elapsed         | 237         |
|    total_timesteps      | 475136      |
| train/                  |             |
|    approx_kl            | 0.009463234 |
|    clip_fraction        | 0.103       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.8        |
|    explained_variance   | 0.494       |
|    learning_rate        | 0.000286    |
|    loss                 | -0.0754     |
|    n_updates            | 280         |
|    policy_gradient_loss | -0.0156     |
|    std                  | 0.887       |
|    value_loss           | 0.0554      |
-----------------------------------------
[2K-----------------------------------------m[38;2;249;38;114m╸[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m490,624/10,000,000 [0m [ [33m0:04:21[0m < [36m0:43:50[0m , [31m3,617 it/s[0m ]
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | 129         |
| time/                   |             |
|    fps                  | 2023        |
|    iterations           | 30          |
|    time_elapsed         | 242         |
|    total_timesteps      | 491520      |
| train/                  |             |
|    approx_kl            | 0.007839621 |
|    clip_fraction        | 0.0851      |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.76       |
|    explained_variance   | 0.38        |
|    learning_rate        | 0.000286    |
|    loss                 | -0.0723     |
|    n_updates            | 290         |
|    policy_gradient_loss | -0.0133     |
|    std                  | 0.881       |
|    value_loss           | 0.0544      |
-----------------------------------------
[2K-----------------------------------------m[38;2;249;38;114m╸[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m507,296/10,000,000 [0m [ [33m0:04:26[0m < [36m0:45:35[0m , [31m3,472 it/s[0m ]
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | 168         |
| time/                   |             |
|    fps                  | 2043        |
|    iterations           | 31          |
|    time_elapsed         | 248         |
|    total_timesteps      | 507904      |
| train/                  |             |
|    approx_kl            | 0.008049769 |
|    clip_fraction        | 0.0848      |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.71       |
|    explained_variance   | 0.441       |
|    learning_rate        | 0.000285    |
|    loss                 | -0.0774     |
|    n_updates            | 300         |
|    policy_gradient_loss | -0.0135     |
|    std                  | 0.874       |
|    value_loss           | 0.056       |
-----------------------------------------
[2KEval num_timesteps=512000, episode_reward=143.99 +/- 13.14m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m511,984/10,000,000 [0m [ [33m0:05:05[0m < [36m3:29:30[0m , [31m755 it/s[0m ]s[0m ]
[2KEpisode length: 1000.00 +/- 0.00━━━[0m[38;5;237m╺[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m511,984/10,000,000 [0m [ [33m0:05:05[0m < [36m3:29:30[0m , [31m755 it/s[0m ]
[2K-----------------------------------------38;5;237m╺[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m511,984/10,000,000 [0m [ [33m0:05:05[0m < [36m3:29:30[0m , [31m755 it/s[0m ]
| eval/                   |             |
|    mean_ep_length       | 1e+03       |
|    mean_reward          | 144         |
| time/                   |             |
|    total_timesteps      | 512000      |
| train/                  |             |
|    approx_kl            | 0.008814397 |
|    clip_fraction        | 0.0889      |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.65       |
|    explained_variance   | 0.423       |
|    learning_rate        | 0.000285    |
|    loss                 | -0.0718     |
|    n_updates            | 310         |
|    policy_gradient_loss | -0.0141     |
|    std                  | 0.866       |
|    value_loss           | 0.046       |
-----------------------------------------
[2KNew best mean reward!;38;114m━━━━━━[0m[38;5;237m╺[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m511,984/10,000,000 [0m [ [33m0:05:05[0m < [36m3:29:30[0m , [31m755 it/s[0m ]
[2K---------------------------------━━━━━━[0m[38;5;237m╺[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m523,568/10,000,000 [0m [ [33m0:05:07[0m < [36m3:46:28[0m , [31m697 it/s[0m ]s[0m ]
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 210      |
| time/              |          |
|    fps             | 1827     |
|    iterations      | 32       |
|    time_elapsed    | 286      |
|    total_timesteps | 524288   |
---------------------------------
[2K-----------------------------------------0m[38;5;237m╺[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m540,240/10,000,000 [0m [ [33m0:05:11[0m < [36m1:54:05[0m , [31m1,382 it/s[0m ]
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | 261         |
| time/                   |             |
|    fps                  | 1860        |
|    iterations           | 33          |
|    time_elapsed         | 290         |
|    total_timesteps      | 540672      |
| train/                  |             |
|    approx_kl            | 0.008782741 |
|    clip_fraction        | 0.096       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.59       |
|    explained_variance   | 0.467       |
|    learning_rate        | 0.000284    |
|    loss                 | -0.0692     |
|    n_updates            | 320         |
|    policy_gradient_loss | -0.0147     |
|    std                  | 0.857       |
|    value_loss           | 0.0453      |
-----------------------------------------
[2K-----------------------------------------0m[38;5;237m╺[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m552,512/10,000,000 [0m [ [33m0:05:14[0m < [36m1:32:06[0m , [31m1,710 it/s[0m ]
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | 307         |
| time/                   |             |
|    fps                  | 1906        |
|    iterations           | 34          |
|    time_elapsed         | 292         |
|    total_timesteps      | 557056      |
| train/                  |             |
|    approx_kl            | 0.008789173 |
|    clip_fraction        | 0.1         |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.53       |
|    explained_variance   | 0.491       |
|    learning_rate        | 0.000284    |
|    loss                 | -0.0821     |
|    n_updates            | 330         |
|    policy_gradient_loss | -0.0146     |
|    std                  | 0.849       |
|    value_loss           | 0.0339      |
-----------------------------------------
[2K-----------------------------------------0m[38;2;249;38;114m╸[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m572,048/10,000,000 [0m [ [33m0:05:18[0m < [36m1:12:59[0m , [31m2,153 it/s[0m ]
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | 354         |
| time/                   |             |
|    fps                  | 1937        |
|    iterations           | 35          |
|    time_elapsed         | 295         |
|    total_timesteps      | 573440      |
| train/                  |             |
|    approx_kl            | 0.009425196 |
|    clip_fraction        | 0.111       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.47       |
|    explained_variance   | 0.521       |
|    learning_rate        | 0.000283    |
|    loss                 | -0.0844     |
|    n_updates            | 340         |
|    policy_gradient_loss | -0.0156     |
|    std                  | 0.84        |
|    value_loss           | 0.0338      |
-----------------------------------------
[2K-----------------------------------------0m[38;2;249;38;114m╸[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m588,736/10,000,000 [0m [ [33m0:05:22[0m < [36m0:34:38[0m , [31m4,530 it/s[0m ]
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | 392         |
| time/                   |             |
|    fps                  | 1967        |
|    iterations           | 36          |
|    time_elapsed         | 299         |
|    total_timesteps      | 589824      |
| train/                  |             |
|    approx_kl            | 0.010145955 |
|    clip_fraction        | 0.109       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.4        |
|    explained_variance   | 0.844       |
|    learning_rate        | 0.000283    |
|    loss                 | -0.0761     |
|    n_updates            | 350         |
|    policy_gradient_loss | -0.0155     |
|    std                  | 0.83        |
|    value_loss           | 0.0315      |
-----------------------------------------
[2K-----------------------------------------[0m[38;5;237m╺[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m605,552/10,000,000 [0m [ [33m0:05:26[0m < [36m0:34:52[0m , [31m4,491 it/s[0m ]s[0m ]
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | 438         |
| time/                   |             |
|    fps                  | 1996        |
|    iterations           | 37          |
|    time_elapsed         | 303         |
|    total_timesteps      | 606208      |
| train/                  |             |
|    approx_kl            | 0.008792974 |
|    clip_fraction        | 0.104       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.34       |
|    explained_variance   | 0.74        |
|    learning_rate        | 0.000282    |
|    loss                 | -0.0852     |
|    n_updates            | 360         |
|    policy_gradient_loss | -0.0142     |
|    std                  | 0.824       |
|    value_loss           | 0.0267      |
-----------------------------------------
[2KEval num_timesteps=614400, episode_reward=865.68 +/- 88.570m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m614,384/10,000,000 [0m [ [33m0:06:07[0m < [36m1:05:43[0m , [31m2,380 it/s[0m ]
[2KEpisode length: 1000.00 +/- 0.00━━━━[0m[38;5;237m╺[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m614,384/10,000,000 [0m [ [33m0:06:07[0m < [36m1:05:43[0m , [31m2,380 it/s[0m ]
[2K-----------------------------------------[38;5;237m╺[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m614,384/10,000,000 [0m [ [33m0:06:07[0m < [36m1:05:43[0m , [31m2,380 it/s[0m ]
| eval/                   |             |
|    mean_ep_length       | 1e+03       |
|    mean_reward          | 866         |
| time/                   |             |
|    total_timesteps      | 614400      |
| train/                  |             |
|    approx_kl            | 0.010384554 |
|    clip_fraction        | 0.106       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.27       |
|    explained_variance   | 0.609       |
|    learning_rate        | 0.000282    |
|    loss                 | -0.0774     |
|    n_updates            | 370         |
|    policy_gradient_loss | -0.0152     |
|    std                  | 0.813       |
|    value_loss           | 0.025       |
-----------------------------------------
[2KNew best mean reward!;249;38;114m━━━━━━━[0m[38;5;237m╺[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m614,384/10,000,000 [0m [ [33m0:06:07[0m < [36m1:05:43[0m , [31m2,380 it/s[0m ]
[2K---------------------------------━━━━━━━[0m[38;5;237m╺[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m621,712/10,000,000 [0m [ [33m0:06:08[0m < [36m9:07:47[0m , [31m285 it/s[0m ]
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 480      |
| time/              |          |
|    fps             | 1811     |
|    iterations      | 38       |
|    time_elapsed    | 343      |
|    total_timesteps | 622592   |
---------------------------------
[2K-----------------------------------------[0m[38;2;249;38;114m╸[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m638,128/10,000,000 [0m [ [33m0:06:12[0m < [36m3:15:37[0m , [31m798 it/s[0m ]
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | 516         |
| time/                   |             |
|    fps                  | 1837        |
|    iterations           | 39          |
|    time_elapsed         | 347         |
|    total_timesteps      | 638976      |
| train/                  |             |
|    approx_kl            | 0.009439752 |
|    clip_fraction        | 0.1         |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.2        |
|    explained_variance   | 0.616       |
|    learning_rate        | 0.000281    |
|    loss                 | -0.0844     |
|    n_updates            | 380         |
|    policy_gradient_loss | -0.014      |
|    std                  | 0.806       |
|    value_loss           | 0.0219      |
-----------------------------------------
[2K-----------------------------------------[0m[38;2;249;38;114m╸[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m654,768/10,000,000 [0m [ [33m0:06:16[0m < [36m0:36:25[0m , [31m4,279 it/s[0m ]
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | 560         |
| time/                   |             |
|    fps                  | 1862        |
|    iterations           | 40          |
|    time_elapsed         | 351         |
|    total_timesteps      | 655360      |
| train/                  |             |
|    approx_kl            | 0.009786431 |
|    clip_fraction        | 0.1         |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.14       |
|    explained_variance   | 0.628       |
|    learning_rate        | 0.000281    |
|    loss                 | -0.0828     |
|    n_updates            | 390         |
|    policy_gradient_loss | -0.0156     |
|    std                  | 0.797       |
|    value_loss           | 0.0216      |
-----------------------------------------
[2K-----------------------------------------[0m[38;2;249;38;114m╸[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m656,016/10,000,000 [0m [ [33m0:06:18[0m < [36m0:42:44[0m , [31m3,644 it/s[0m ]
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | 603         |
| time/                   |             |
|    fps                  | 1899        |
|    iterations           | 41          |
|    time_elapsed         | 353         |
|    total_timesteps      | 671744      |
| train/                  |             |
|    approx_kl            | 0.008802819 |
|    clip_fraction        | 0.0997      |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.07       |
|    explained_variance   | 0.599       |
|    learning_rate        | 0.00028     |
|    loss                 | -0.0822     |
|    n_updates            | 400         |
|    policy_gradient_loss | -0.0143     |
|    std                  | 0.788       |
|    value_loss           | 0.0198      |
-----------------------------------------
[2K-----------------------------------------[0m[38;2;249;38;114m╸[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m687,760/10,000,000 [0m [ [33m0:06:25[0m < [36m0:37:50[0m , [31m4,104 it/s[0m ]
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | 689         |
| time/                   |             |
|    fps                  | 1922        |
|    iterations           | 42          |
|    time_elapsed         | 357         |
|    total_timesteps      | 688128      |
| train/                  |             |
|    approx_kl            | 0.010219418 |
|    clip_fraction        | 0.106       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7          |
|    explained_variance   | 0.586       |
|    learning_rate        | 0.00028     |
|    loss                 | -0.0803     |
|    n_updates            | 410         |
|    policy_gradient_loss | -0.0157     |
|    std                  | 0.78        |
|    value_loss           | 0.0196      |
-----------------------------------------
[2K-----------------------------------------[0m[38;5;237m╺[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m703,984/10,000,000 [0m [ [33m0:06:29[0m < [36m0:38:20[0m , [31m4,043 it/s[0m ]s[0m ]
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | 730         |
| time/                   |             |
|    fps                  | 1944        |
|    iterations           | 43          |
|    time_elapsed         | 362         |
|    total_timesteps      | 704512      |
| train/                  |             |
|    approx_kl            | 0.009155685 |
|    clip_fraction        | 0.0996      |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.94       |
|    explained_variance   | 0.538       |
|    learning_rate        | 0.000279    |
|    loss                 | -0.0749     |
|    n_updates            | 420         |
|    policy_gradient_loss | -0.0136     |
|    std                  | 0.773       |
|    value_loss           | 0.0181      |
-----------------------------------------
[2KEval num_timesteps=716800, episode_reward=1362.57 +/- 46.820m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m716,784/10,000,000 [0m [ [33m0:07:06[0m < [36m1:12:41[0m , [31m2,129 it/s[0m ]
[2KEpisode length: 1000.00 +/- 0.00━━━━━[0m[38;5;237m╺[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m716,784/10,000,000 [0m [ [33m0:07:06[0m < [36m1:12:41[0m , [31m2,129 it/s[0m ]
[2K-----------------------------------------[38;5;237m╺[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m716,784/10,000,000 [0m [ [33m0:07:06[0m < [36m1:12:41[0m , [31m2,129 it/s[0m ]
| eval/                   |             |
|    mean_ep_length       | 1e+03       |
|    mean_reward          | 1.36e+03    |
| time/                   |             |
|    total_timesteps      | 716800      |
| train/                  |             |
|    approx_kl            | 0.008687558 |
|    clip_fraction        | 0.0849      |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.89       |
|    explained_variance   | 0.563       |
|    learning_rate        | 0.000279    |
|    loss                 | -0.0748     |
|    n_updates            | 430         |
|    policy_gradient_loss | -0.0124     |
|    std                  | 0.766       |
|    value_loss           | 0.0166      |
-----------------------------------------
[2KNew best mean reward!;38;114m━━━━━━━━[0m[38;5;237m╺[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m716,784/10,000,000 [0m [ [33m0:07:06[0m < [36m1:12:41[0m , [31m2,129 it/s[0m ]
[2K---------------------------------━━━━━━━━[0m[38;5;237m╺[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m720,112/10,000,000 [0m [ [33m0:07:07[0m < [36m15:17:09[0m , [31m169 it/s[0m ]
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 761      |
| time/              |          |
|    fps             | 1812     |
|    iterations      | 44       |
|    time_elapsed    | 397      |
|    total_timesteps | 720896   |
---------------------------------
[2K-----------------------------------------[0m[38;2;249;38;114m╸[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m736,352/10,000,000 [0m [ [33m0:07:11[0m < [36m3:07:39[0m , [31m823 it/s[0m ]
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | 797         |
| time/                   |             |
|    fps                  | 1834        |
|    iterations           | 45          |
|    time_elapsed         | 401         |
|    total_timesteps      | 737280      |
| train/                  |             |
|    approx_kl            | 0.008782181 |
|    clip_fraction        | 0.0893      |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.83       |
|    explained_variance   | 0.949       |
|    learning_rate        | 0.000278    |
|    loss                 | -0.0813     |
|    n_updates            | 440         |
|    policy_gradient_loss | -0.0136     |
|    std                  | 0.759       |
|    value_loss           | 0.0159      |
-----------------------------------------
[2K-----------------------------------------[0m[38;2;249;38;114m╸[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m752,944/10,000,000 [0m [ [33m0:07:15[0m < [36m2:00:32[0m , [31m1,279 it/s[0m ]
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | 829         |
| time/                   |             |
|    fps                  | 1855        |
|    iterations           | 46          |
|    time_elapsed         | 406         |
|    total_timesteps      | 753664      |
| train/                  |             |
|    approx_kl            | 0.009678319 |
|    clip_fraction        | 0.107       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.76       |
|    explained_variance   | 0.522       |
|    learning_rate        | 0.000278    |
|    loss                 | -0.082      |
|    n_updates            | 450         |
|    policy_gradient_loss | -0.0144     |
|    std                  | 0.751       |
|    value_loss           | 0.0144      |
-----------------------------------------
[2K-----------------------------------------[0m[38;2;249;38;114m╸[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m769,328/10,000,000 [0m [ [33m0:07:20[0m < [36m0:39:04[0m , [31m3,939 it/s[0m ]
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | 862         |
| time/                   |             |
|    fps                  | 1875        |
|    iterations           | 47          |
|    time_elapsed         | 410         |
|    total_timesteps      | 770048      |
| train/                  |             |
|    approx_kl            | 0.008835591 |
|    clip_fraction        | 0.0984      |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.69       |
|    explained_variance   | 0.488       |
|    learning_rate        | 0.000277    |
|    loss                 | -0.0884     |
|    n_updates            | 460         |
|    policy_gradient_loss | -0.0136     |
|    std                  | 0.742       |
|    value_loss           | 0.0122      |
-----------------------------------------
[2K-----------------------------------------━[0m[38;5;237m╺[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m779,264/10,000,000 [0m [ [33m0:07:23[0m < [36m0:40:38[0m , [31m3,783 it/s[0m ]s[0m ]
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | 888         |
| time/                   |             |
|    fps                  | 1907        |
|    iterations           | 48          |
|    time_elapsed         | 412         |
|    total_timesteps      | 786432      |
| train/                  |             |
|    approx_kl            | 0.008439836 |
|    clip_fraction        | 0.0983      |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.66       |
|    explained_variance   | 0.544       |
|    learning_rate        | 0.000277    |
|    loss                 | -0.0813     |
|    n_updates            | 470         |
|    policy_gradient_loss | -0.0135     |
|    std                  | 0.74        |
|    value_loss           | 0.0117      |
-----------------------------------------
[2K------------------------------------------[0m[38;5;237m╺[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m802,416/10,000,000 [0m [ [33m0:07:28[0m < [36m0:38:33[0m , [31m3,978 it/s[0m ]
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | 900          |
| time/                   |              |
|    fps                  | 1928         |
|    iterations           | 49           |
|    time_elapsed         | 416          |
|    total_timesteps      | 802816       |
| train/                  |              |
|    approx_kl            | 0.0084345415 |
|    clip_fraction        | 0.0932       |
|    clip_range           | 0.2          |
|    entropy_loss         | -6.62        |
|    explained_variance   | 0.54         |
|    learning_rate        | 0.000276     |
|    loss                 | -0.0799      |
|    n_updates            | 480          |
|    policy_gradient_loss | -0.0123      |
|    std                  | 0.735        |
|    value_loss           | 0.0121       |
------------------------------------------
[2KEval num_timesteps=819200, episode_reward=1376.35 +/- 48.00;114m╸[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m819,184/10,000,000 [0m [ [33m0:08:05[0m < [36m1:38:23[0m , [31m1,555 it/s[0m ]
[2KEpisode length: 1000.00 +/- 0.00━━━━━━[0m[38;2;249;38;114m╸[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m819,184/10,000,000 [0m [ [33m0:08:05[0m < [36m1:38:23[0m , [31m1,555 it/s[0m ]
[2K----------------------------------------0m[38;2;249;38;114m╸[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m819,184/10,000,000 [0m [ [33m0:08:05[0m < [36m1:38:23[0m , [31m1,555 it/s[0m ]
| eval/                   |            |
|    mean_ep_length       | 1e+03      |
|    mean_reward          | 1.38e+03   |
| time/                   |            |
|    total_timesteps      | 819200     |
| train/                  |            |
|    approx_kl            | 0.00913601 |
|    clip_fraction        | 0.0975     |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.57      |
|    explained_variance   | 0.965      |
|    learning_rate        | 0.000276   |
|    loss                 | -0.0709    |
|    n_updates            | 490        |
|    policy_gradient_loss | -0.0125    |
|    std                  | 0.73       |
|    value_loss           | 0.00991    |
----------------------------------------
[2KNew best mean reward!;38;114m━━━━━━━━━[0m[38;2;249;38;114m╸[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m819,184/10,000,000 [0m [ [33m0:08:05[0m < [36m1:38:23[0m , [31m1,555 it/s[0m ]
[2K---------------------------------━━━━━━━━━[0m[38;2;249;38;114m╸[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m819,184/10,000,000 [0m [ [33m0:08:05[0m < [36m1:38:23[0m , [31m1,555 it/s[0m ]
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 934      |
| time/              |          |
|    fps             | 1816     |
|    iterations      | 50       |
|    time_elapsed    | 450      |
|    total_timesteps | 819200   |
---------------------------------
[2K-----------------------------------------━[0m[38;2;249;38;114m╸[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m834,608/10,000,000 [0m [ [33m0:08:09[0m < [36m2:50:39[0m , [31m895 it/s[0m ]
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | 940         |
| time/                   |             |
|    fps                  | 1835        |
|    iterations           | 51          |
|    time_elapsed         | 455         |
|    total_timesteps      | 835584      |
| train/                  |             |
|    approx_kl            | 0.008995358 |
|    clip_fraction        | 0.0941      |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.52       |
|    explained_variance   | 0.698       |
|    learning_rate        | 0.000275    |
|    loss                 | -0.0724     |
|    n_updates            | 500         |
|    policy_gradient_loss | -0.0124     |
|    std                  | 0.724       |
|    value_loss           | 0.0105      |
-----------------------------------------
[2K-----------------------------------------━[0m[38;2;249;38;114m╸[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m851,056/10,000,000 [0m [ [33m0:08:13[0m < [36m1:42:38[0m , [31m1,486 it/s[0m ]
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | 962         |
| time/                   |             |
|    fps                  | 1854        |
|    iterations           | 52          |
|    time_elapsed         | 459         |
|    total_timesteps      | 851968      |
| train/                  |             |
|    approx_kl            | 0.008502863 |
|    clip_fraction        | 0.0867      |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.48       |
|    explained_variance   | 0.97        |
|    learning_rate        | 0.000275    |
|    loss                 | -0.0781     |
|    n_updates            | 510         |
|    policy_gradient_loss | -0.012      |
|    std                  | 0.72        |
|    value_loss           | 0.00936     |
-----------------------------------------
[2K-----------------------------------------━━[0m[38;5;237m╺[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m868,256/10,000,000 [0m [ [33m0:08:17[0m < [36m1:19:24[0m , [31m1,917 it/s[0m ]s[0m ]
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | 980         |
| time/                   |             |
|    fps                  | 1873        |
|    iterations           | 53          |
|    time_elapsed         | 463         |
|    total_timesteps      | 868352      |
| train/                  |             |
|    approx_kl            | 0.008888392 |
|    clip_fraction        | 0.0947      |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.42       |
|    explained_variance   | 0.41        |
|    learning_rate        | 0.000274    |
|    loss                 | -0.081      |
|    n_updates            | 520         |
|    policy_gradient_loss | -0.0116     |
|    std                  | 0.714       |
|    value_loss           | 0.00797     |
-----------------------------------------
[2K-----------------------------------------━━[0m[38;5;237m╺[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m883,488/10,000,000 [0m [ [33m0:08:21[0m < [36m1:09:24[0m , [31m2,190 it/s[0m ]
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | 1e+03       |
| time/                   |             |
|    fps                  | 1893        |
|    iterations           | 54          |
|    time_elapsed         | 467         |
|    total_timesteps      | 884736      |
| train/                  |             |
|    approx_kl            | 0.008457415 |
|    clip_fraction        | 0.0867      |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.37       |
|    explained_variance   | 0.458       |
|    learning_rate        | 0.000274    |
|    loss                 | -0.0807     |
|    n_updates            | 530         |
|    policy_gradient_loss | -0.0106     |
|    std                  | 0.708       |
|    value_loss           | 0.00739     |
-----------------------------------------
[2K------------------------------------------━[0m[38;5;237m╺[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m900,592/10,000,000 [0m [ [33m0:08:25[0m < [36m0:37:42[0m , [31m4,024 it/s[0m ]
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | 1.02e+03     |
| time/                   |              |
|    fps                  | 1911         |
|    iterations           | 55           |
|    time_elapsed         | 471          |
|    total_timesteps      | 901120       |
| train/                  |              |
|    approx_kl            | 0.0085746385 |
|    clip_fraction        | 0.0956       |
|    clip_range           | 0.2          |
|    entropy_loss         | -6.31        |
|    explained_variance   | 0.474        |
|    learning_rate        | 0.000273     |
|    loss                 | -0.0716      |
|    n_updates            | 540          |
|    policy_gradient_loss | -0.0126      |
|    std                  | 0.701        |
|    value_loss           | 0.00784      |
------------------------------------------
[2K-----------------------------------------━━[0m[38;2;249;38;114m╸[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m906,496/10,000,000 [0m [ [33m0:08:27[0m < [36m0:39:06[0m , [31m3,877 it/s[0m ]
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | 1.05e+03    |
| time/                   |             |
|    fps                  | 1940        |
|    iterations           | 56          |
|    time_elapsed         | 472         |
|    total_timesteps      | 917504      |
| train/                  |             |
|    approx_kl            | 0.009206091 |
|    clip_fraction        | 0.0927      |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.25       |
|    explained_variance   | 0.486       |
|    learning_rate        | 0.000273    |
|    loss                 | -0.0781     |
|    n_updates            | 550         |
|    policy_gradient_loss | -0.0129     |
|    std                  | 0.695       |
|    value_loss           | 0.00798     |
-----------------------------------------
[2KEval num_timesteps=921600, episode_reward=1430.76 +/- 58.448;114m╸[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m921,584/10,000,000 [0m [ [33m0:09:02[0m < [36m1:16:53[0m , [31m1,968 it/s[0m ]
[2KEpisode length: 1000.00 +/- 0.00━━━━━━━[0m[38;2;249;38;114m╸[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m921,584/10,000,000 [0m [ [33m0:09:02[0m < [36m1:16:53[0m , [31m1,968 it/s[0m ]
[2K-----------------------------------------0m[38;2;249;38;114m╸[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m921,584/10,000,000 [0m [ [33m0:09:02[0m < [36m1:16:53[0m , [31m1,968 it/s[0m ]
| eval/                   |             |
|    mean_ep_length       | 1e+03       |
|    mean_reward          | 1.43e+03    |
| time/                   |             |
|    total_timesteps      | 921600      |
| train/                  |             |
|    approx_kl            | 0.008853782 |
|    clip_fraction        | 0.0961      |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.19       |
|    explained_variance   | 0.459       |
|    learning_rate        | 0.000272    |
|    loss                 | -0.0814     |
|    n_updates            | 560         |
|    policy_gradient_loss | -0.0117     |
|    std                  | 0.688       |
|    value_loss           | 0.00797     |
-----------------------------------------
[2KNew best mean reward!;249;38;114m━━━━━━━━━━[0m[38;2;249;38;114m╸[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m921,584/10,000,000 [0m [ [33m0:09:02[0m < [36m1:16:53[0m , [31m1,968 it/s[0m ]
[2K---------------------------------━━━━━━━━━━━[0m[38;5;237m╺[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m933,360/10,000,000 [0m [ [33m0:09:04[0m < [36m3:48:02[0m , [31m663 it/s[0m ]s[0m ]
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 1.07e+03 |
| time/              |          |
|    fps             | 1846     |
|    iterations      | 57       |
|    time_elapsed    | 505      |
|    total_timesteps | 933888   |
---------------------------------
[2K-----------------------------------------━━━[0m[38;5;237m╺[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m949,632/10,000,000 [0m [ [33m0:09:08[0m < [36m1:57:43[0m , [31m1,281 it/s[0m ]s[0m ]
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | 1.09e+03    |
| time/                   |             |
|    fps                  | 1863        |
|    iterations           | 58          |
|    time_elapsed         | 509         |
|    total_timesteps      | 950272      |
| train/                  |             |
|    approx_kl            | 0.008668406 |
|    clip_fraction        | 0.101       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.12       |
|    explained_variance   | 0.418       |
|    learning_rate        | 0.000272    |
|    loss                 | -0.0773     |
|    n_updates            | 570         |
|    policy_gradient_loss | -0.0122     |
|    std                  | 0.681       |
|    value_loss           | 0.00723     |
-----------------------------------------
[2K-----------------------------------------━━━[0m[38;5;237m╺[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m965,744/10,000,000 [0m [ [33m0:09:12[0m < [36m1:28:24[0m , [31m1,703 it/s[0m ]
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | 1.1e+03     |
| time/                   |             |
|    fps                  | 1880        |
|    iterations           | 59          |
|    time_elapsed         | 514         |
|    total_timesteps      | 966656      |
| train/                  |             |
|    approx_kl            | 0.008854993 |
|    clip_fraction        | 0.0939      |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.08       |
|    explained_variance   | 0.395       |
|    learning_rate        | 0.000271    |
|    loss                 | -0.0848     |
|    n_updates            | 580         |
|    policy_gradient_loss | -0.0105     |
|    std                  | 0.679       |
|    value_loss           | 0.00618     |
-----------------------------------------
[2K-----------------------------------------━━━[0m[38;5;237m╺[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m981,696/10,000,000 [0m [ [33m0:09:16[0m < [36m1:14:22[0m , [31m2,021 it/s[0m ]
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | 1.12e+03    |
| time/                   |             |
|    fps                  | 1898        |
|    iterations           | 60          |
|    time_elapsed         | 517         |
|    total_timesteps      | 983040      |
| train/                  |             |
|    approx_kl            | 0.008439243 |
|    clip_fraction        | 0.089       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.04       |
|    explained_variance   | 0.444       |
|    learning_rate        | 0.000271    |
|    loss                 | -0.0683     |
|    n_updates            | 590         |
|    policy_gradient_loss | -0.0117     |
|    std                  | 0.673       |
|    value_loss           | 0.0067      |
-----------------------------------------
[2K-----------------------------------------━━━[0m[38;2;249;38;114m╸[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m999,072/10,000,000 [0m [ [33m0:09:20[0m < [36m0:34:35[0m , [31m4,339 it/s[0m ]
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | 1.13e+03    |
| time/                   |             |
|    fps                  | 1915        |
|    iterations           | 61          |
|    time_elapsed         | 521         |
|    total_timesteps      | 999424      |
| train/                  |             |
|    approx_kl            | 0.008967394 |
|    clip_fraction        | 0.0888      |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.01       |
|    explained_variance   | 0.417       |
|    learning_rate        | 0.000271    |
|    loss                 | -0.0636     |
|    n_updates            | 600         |
|    policy_gradient_loss | -0.0113     |
|    std                  | 0.67        |
|    value_loss           | 0.00627     |
-----------------------------------------
[2K-----------------------------------------━━━[0m[38;2;249;38;114m╸[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m1,015,008/10,000,000 [0m [ [33m0:09:24[0m < [36m0:34:49[0m , [31m4,301 it/s[0m ]
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | 1.14e+03    |
| time/                   |             |
|    fps                  | 1932        |
|    iterations           | 62          |
|    time_elapsed         | 525         |
|    total_timesteps      | 1015808     |
| train/                  |             |
|    approx_kl            | 0.008437151 |
|    clip_fraction        | 0.0938      |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.97       |
|    explained_variance   | 0.465       |
|    learning_rate        | 0.00027     |
|    loss                 | -0.0722     |
|    n_updates            | 610         |
|    policy_gradient_loss | -0.00969    |
|    std                  | 0.665       |
|    value_loss           | 0.00658     |
-----------------------------------------
[2KTraceback (most recent call last):━━━━━━━━━━[0m[38;2;249;38;114m╸[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m1,023,984/10,000,000 [0m [ [33m0:09:49[0m < [36m1:06:21[0m , [31m2,255 it/s[0m ]
[2K  File "/mnt/c/Users/yuvra/OneDrive/Desktop/Work/pytorch/RL/PPO/MuJoCo/benchmark/SB3/half-cheetah-sb3.py", line 229, in <module>━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m1,023,984/10,000,000 [0m [ [33m0:09:49[0m < [36m1:06:21[0m , [31m2,255 it/s[0m ]
    model.learn(
[2K  File "/home/yuvrajsingh/anaconda3/envs/mt/lib/python3.11/site-packages/stable_baselines3/ppo/ppo.py", line 311, in learn━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m1,023,984/10,000,000 [0m [ [33m0:09:49[0m < [36m1:06:21[0m , [31m2,255 it/s[0m ]
    return super().learn(
           ^^^^^^^^^^^^^^
[2K  File "/home/yuvrajsingh/anaconda3/envs/mt/lib/python3.11/site-packages/stable_baselines3/common/on_policy_algorithm.py", line 324, in learn━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m1,023,984/10,000,000 [0m [ [33m0:09:49[0m < [36m1:06:21[0m , [31m2,255 it/s[0m ]
    continue_training = self.collect_rollouts(self.env, callback, self.rollout_buffer, n_rollout_steps=self.n_steps)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2K  File "/home/yuvrajsingh/anaconda3/envs/mt/lib/python3.11/site-packages/stable_baselines3/common/on_policy_algorithm.py", line 224, in collect_rollouts━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m1,023,984/10,000,000 [0m [ [33m0:09:49[0m < [36m1:06:21[0m , [31m2,255 it/s[0m ]
    if not callback.on_step():
           ^^^^^^^^^^^^^^^^^^
[2K  File "/home/yuvrajsingh/anaconda3/envs/mt/lib/python3.11/site-packages/stable_baselines3/common/callbacks.py", line 114, in on_step━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m1,023,984/10,000,000 [0m [ [33m0:09:49[0m < [36m1:06:21[0m , [31m2,255 it/s[0m ]
    return self._on_step()
           ^^^^^^^^^^^^^^^
[2K  File "/home/yuvrajsingh/anaconda3/envs/mt/lib/python3.11/site-packages/stable_baselines3/common/callbacks.py", line 223, in _on_step━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m1,023,984/10,000,000 [0m [ [33m0:09:49[0m < [36m1:06:21[0m , [31m2,255 it/s[0m ]
    continue_training = callback.on_step() and continue_training
                        ^^^^^^^^^^^^^^^^^^
[2K  File "/home/yuvrajsingh/anaconda3/envs/mt/lib/python3.11/site-packages/stable_baselines3/common/callbacks.py", line 114, in on_step━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m1,023,984/10,000,000 [0m [ [33m0:09:49[0m < [36m1:06:21[0m , [31m2,255 it/s[0m ]
    return self._on_step()
           ^^^^^^^^^^^^^^^
[2K  File "/home/yuvrajsingh/anaconda3/envs/mt/lib/python3.11/site-packages/stable_baselines3/common/callbacks.py", line 223, in _on_step━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m1,023,984/10,000,000 [0m [ [33m0:09:49[0m < [36m1:06:21[0m , [31m2,255 it/s[0m ]
    continue_training = callback.on_step() and continue_training
                        ^^^^^^^^^^^^^^^^^^
[2K  File "/home/yuvrajsingh/anaconda3/envs/mt/lib/python3.11/site-packages/stable_baselines3/common/callbacks.py", line 114, in on_step━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m1,023,984/10,000,000 [0m [ [33m0:09:49[0m < [36m1:06:21[0m , [31m2,255 it/s[0m ]
    return self._on_step()
           ^^^^^^^^^^^^^^^
[2K  File "/home/yuvrajsingh/anaconda3/envs/mt/lib/python3.11/site-packages/stable_baselines3/common/callbacks.py", line 464, in _on_step━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m1,023,984/10,000,000 [0m [ [33m0:09:49[0m < [36m1:06:21[0m , [31m2,255 it/s[0m ]
    episode_rewards, episode_lengths = evaluate_policy(
                                       ^^^^^^^^^^^^^^^^
[2K  File "/home/yuvrajsingh/anaconda3/envs/mt/lib/python3.11/site-packages/stable_baselines3/common/evaluation.py", line 88, in evaluate_policy━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m1,023,984/10,000,000 [0m [ [33m0:09:49[0m < [36m1:06:21[0m , [31m2,255 it/s[0m ]
    actions, states = model.predict(
                      ^^^^^^^^^^^^^^
[2K  File "/home/yuvrajsingh/anaconda3/envs/mt/lib/python3.11/site-packages/stable_baselines3/common/base_class.py", line 557, in predict━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m1,023,984/10,000,000 [0m [ [33m0:09:49[0m < [36m1:06:21[0m , [31m2,255 it/s[0m ]
    return self.policy.predict(observation, state, episode_start, deterministic)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2K  File "/home/yuvrajsingh/anaconda3/envs/mt/lib/python3.11/site-packages/stable_baselines3/common/policies.py", line 368, in predict━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m1,023,984/10,000,000 [0m [ [33m0:09:49[0m < [36m1:06:21[0m , [31m2,255 it/s[0m ]
    actions = self._predict(obs_tensor, deterministic=deterministic)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2K  File "/home/yuvrajsingh/anaconda3/envs/mt/lib/python3.11/site-packages/stable_baselines3/common/policies.py", line 717, in _predict━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m1,023,984/10,000,000 [0m [ [33m0:09:49[0m < [36m1:06:21[0m , [31m2,255 it/s[0m ]
    return self.get_distribution(observation).get_actions(deterministic=deterministic)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2K  File "/home/yuvrajsingh/anaconda3/envs/mt/lib/python3.11/site-packages/stable_baselines3/common/policies.py", line 751, in get_distribution━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m1,023,984/10,000,000 [0m [ [33m0:09:49[0m < [36m1:06:21[0m , [31m2,255 it/s[0m ]
    latent_pi = self.mlp_extractor.forward_actor(features)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2K  File "/home/yuvrajsingh/anaconda3/envs/mt/lib/python3.11/site-packages/stable_baselines3/common/torch_layers.py", line 260, in forward_actor━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m1,023,984/10,000,000 [0m [ [33m0:09:49[0m < [36m1:06:21[0m , [31m2,255 it/s[0m ]
    return self.policy_net(features)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
[2K  File "/home/yuvrajsingh/anaconda3/envs/mt/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m1,023,984/10,000,000 [0m [ [33m0:09:49[0m < [36m1:06:21[0m , [31m2,255 it/s[0m ]
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2K  File "/home/yuvrajsingh/anaconda3/envs/mt/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m1,023,984/10,000,000 [0m [ [33m0:09:49[0m < [36m1:06:21[0m , [31m2,255 it/s[0m ]
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2K  File "/home/yuvrajsingh/anaconda3/envs/mt/lib/python3.11/site-packages/torch/nn/modules/container.py", line 250, in forward━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m1,023,984/10,000,000 [0m [ [33m0:09:49[0m < [36m1:06:21[0m , [31m2,255 it/s[0m ]
    input = module(input)
            ^^^^^^^^^^^^^
[2K  File "/home/yuvrajsingh/anaconda3/envs/mt/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m1,023,984/10,000,000 [0m [ [33m0:09:49[0m < [36m1:06:21[0m , [31m2,255 it/s[0m ]
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2K  File "/home/yuvrajsingh/anaconda3/envs/mt/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m1,023,984/10,000,000 [0m [ [33m0:09:49[0m < [36m1:06:21[0m , [31m2,255 it/s[0m ]
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2K  File "/home/yuvrajsingh/anaconda3/envs/mt/lib/python3.11/site-packages/torch/nn/modules/linear.py", line 125, in forward━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m1,023,984/10,000,000 [0m [ [33m0:09:49[0m < [36m1:06:21[0m , [31m2,255 it/s[0m ]
    return F.linear(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2KKeyboardInterrupt;249;38;114m━━━━━━━━━━━[0m[38;2;249;38;114m╸[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m1,023,984/10,000,000 [0m [ [33m0:09:49[0m < [36m1:06:21[0m , [31m2,255 it/s[0m ]
[2KException ignored in atexit callback: <function _start_and_connect_service.<locals>.teardown_atexit at 0x7fdba770d1c0>━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m1,023,984/10,000,000 [0m [ [33m0:09:49[0m < [36m1:06:21[0m , [31m2,255 it/s[0m ]
[2KTraceback (most recent call last):━━━━━━[0m[38;2;249;38;114m╸[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m1,023,984/10,000,000 [0m [ [33m0:09:49[0m < [36m1:06:21[0m , [31m2,255 it/s[0m ]
[2K  File "/home/yuvrajsingh/anaconda3/envs/mt/lib/python3.11/site-packages/wandb/sdk/lib/service_connection.py", line 94, in teardown_atexit━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m1,023,984/10,000,000 [0m [ [33m0:09:49[0m < [36m1:06:21[0m , [31m2,255 it/s[0m ]
[2K    conn.teardown(hooks.exit_code)━━━━━━[0m[38;2;249;38;114m╸[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m1,023,984/10,000,000 [0m [ [33m0:09:49[0m < [36m1:06:21[0m , [31m2,255 it/s[0m ]
[2K  File "/home/yuvrajsingh/anaconda3/envs/mt/lib/python3.11/site-packages/wandb/sdk/lib/service_connection.py", line 226, in teardown━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m1,023,984/10,000,000 [0m [ [33m0:09:49[0m < [36m1:06:21[0m , [31m2,255 it/s[0m ]
[2K    self._router.join()8;114m━━━━━━━━━━━[0m[38;2;249;38;114m╸[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m1,023,984/10,000,000 [0m [ [33m0:09:49[0m < [36m1:06:21[0m , [31m2,255 it/s[0m ]
[2K  File "/home/yuvrajsingh/anaconda3/envs/mt/lib/python3.11/site-packages/wandb/sdk/interface/router.py", line 75, in join━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m1,023,984/10,000,000 [0m [ [33m0:09:49[0m < [36m1:06:21[0m , [31m2,255 it/s[0m ]
[2K    self._thread.join()49;38;114m━━━━━━━━━━━[0m[38;2;249;38;114m╸[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m1,023,984/10,000,000 [0m [ [33m0:09:49[0m < [36m1:06:21[0m , [31m2,255 it/s[0m ]
[2K  File "/home/yuvrajsingh/anaconda3/envs/mt/lib/python3.11/threading.py", line 1119, in join━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m1,023,984/10,000,000 [0m [ [33m0:09:49[0m < [36m1:06:21[0m , [31m2,255 it/s[0m ]
[2K    self._wait_for_tstate_lock()━━━━━━━━[0m[38;2;249;38;114m╸[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m1,023,984/10,000,000 [0m [ [33m0:09:49[0m < [36m1:06:21[0m , [31m2,255 it/s[0m ]
[2K  File "/home/yuvrajsingh/anaconda3/envs/mt/lib/python3.11/threading.py", line 1139, in _wait_for_tstate_lock━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m1,023,984/10,000,000 [0m [ [33m0:09:49[0m < [36m1:06:21[0m , [31m2,255 it/s[0m ]
[2K    if lock.acquire(block, timeout):━━━━[0m[38;2;249;38;114m╸[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m1,023,984/10,000,000 [0m [ [33m0:09:49[0m < [36m1:06:21[0m , [31m2,255 it/s[0m ]
[2K       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^━━━━━[0m[38;2;249;38;114m╸[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m1,023,984/10,000,000 [0m [ [33m0:09:49[0m < [36m1:06:21[0m , [31m2,255 it/s[0m ]
[2KKeyboardInterrupt: 49;38;114m━━━━━━━━━━━[0m[38;2;249;38;114m╸[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m1,023,984/10,000,000 [0m [ [33m0:09:49[0m < [36m1:06:21[0m , [31m2,255 it/s[0m ]
[2KException ignored in atexit callback: <bound method finalize._exitfunc of <class 'weakref.finalize'>>━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m1,023,984/10,000,000 [0m [ [33m0:09:50[0m < [36m1:06:21[0m , [31m2,255 it/s[0m ]
[2KTraceback (most recent call last):━━━━━━[0m[38;2;249;38;114m╸[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m1,023,984/10,000,000 [0m [ [33m0:09:50[0m < [36m1:06:21[0m , [31m2,255 it/s[0m ]
[2K  File "/home/yuvrajsingh/anaconda3/envs/mt/lib/python3.11/weakref.py", line 666, in _exitfunc━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m1,023,984/10,000,000 [0m [ [33m0:09:50[0m < [36m1:06:21[0m , [31m2,255 it/s[0m ]
[2K    f()[0m [38;2;249;38;114m━━━━━━━━━━━[0m[38;2;249;38;114m╸[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m1,023,984/10,000,000 [0m [ [33m0:09:50[0m < [36m1:06:21[0m , [31m2,255 it/s[0m ]
[2K  File "/home/yuvrajsingh/anaconda3/envs/mt/lib/python3.11/weakref.py", line 590, in __call__━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m1,023,984/10,000,000 [0m [ [33m0:09:50[0m < [36m1:06:21[0m , [31m2,255 it/s[0m ]
[2K    return info.func(*info.args, **(info.kwargs or {}))38;114m╸[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m1,023,984/10,000,000 [0m [ [33m0:09:50[0m < [36m1:06:21[0m , [31m2,255 it/s[0m ]
[2K           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^38;114m╸[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m1,023,984/10,000,000 [0m [ [33m0:09:50[0m < [36m1:06:21[0m , [31m2,255 it/s[0m ]
[2KKeyboardInterrupt: 49;38;114m━━━━━━━━━━━[0m[38;2;249;38;114m╸[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m1,023,984/10,000,000 [0m [ [33m0:09:50[0m < [36m1:06:21[0m , [31m2,255 it/s[0m ]
[35m  10%[0m [38;2;249;38;114m━━━━━━━━━━━[0m[38;2;249;38;114m╸[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m1,023,984/10,000,000 [0m [ [33m0:09:50[0m < [36m1:06:21[0m , [31m2,255 it/s[0m ]
